=====
note
=====
question:

does splitting critical edges change the splitting of live ranges? for
example look at fmin.i where splitting critical edges makes chow fail
an insertion on multiple defs..

it seems that splitting critical edges can change the number of
interferences in a live range. This happens when the block for the 
split critical edge is added to a live range to extend its range. This
will happen when the live range is split and adds the extra block even
though it is not needed.

L1:
  z
  BRANCH L2 L3
  
L2:
  y
  GOTO L3

L3:
  y
  x
  END

with split critical edges in this case both x and z extend to the
dummy block L4, which increases their interferences. this can happen
with bad splitting (by adding a block when there is no subsequent use
(z) and adding a block before the first use (x)

L1:
  z
  BRANCH L2 L4
  
L2:
  y
  GOTO L3

L4:
  z
  x
  GOTO L3

L3:
  y
  x


=====
note
=====
it makes a big difference where you choose your split point,
otherwise you can end up with a bunch of live units with no uses and
no defs and the whole live range contains these useless units. i think
that is the cause of the "peeling" splitting we saw where it would
peel off on of the live units each time it would split, but that would
not help since it is a useless live unit


=====
note
=====
question:
why are we not putting the loads and stores in the right place? we are
calculating stores by looking at the uses that each def reaches. if it
reaches a use in another live range then we add a store. if it reaches
a use in the same live range that needs a load we add a store.

we compute loads by looking at the predecessor blocks. if the
predecessor is in another live range then we insert a load.

answer:
phi nodes were getting in the way. if a def reaches a use that is a
phi-node it is not a real use. we need to look at the uses that the
phi-node def reaches as well in order to find all the nodes that def
actually reaches.

=====
note
=====
speed up attemtps: 
 + use a set to for interferece "list" so that adding unique values is
 efficent (log n)

 + choose the starting point for the split much better
   - only split starting with a def or a use
   - split starting with an entry point if possible

 + a live range is uncolorable if all the live units where it actually
 has a use or a def have no available registers

 + only need to update interferences for the new and orig lr and those
 live ranges that they interfered with. can be done efficently by
 iterating over the origlr interferences and seeing what they now
 interfere with


=====
note
=====
observation:

it seems that the splitting algorithm can add live units to the split
live range even when there is no point. we split the live range by
looking for a place where it starts with a def or a use and then do a
bfs of the nodes in the origlr from there adding any node that does
not fill up the forbidden register set. now suppose that we don't get
to another use of the live range in any block that we add, this means
that if we allocate this split live range it could tie up all those
blocks even though it serves no purpose to have that register tied up
since there are no uses beyond the first.

I suspect that the priority function is designed to prevent this from
happening, but it is something to watch for.


=====
note
=====
question:

Would it be beneficial to split the BB at register to register copies?



=====
note
=====
Had a problem where a load was inserted for a live range because it
had a predecessor that was not in the live range, but no store was
inserted in any of the other blocks in the live range. Turns out the
load was requested because it was used in a phi-node, but no store was
generated because we were not counting phi-node uses. 

not sure how exactly this should be handeled. need to better figure
out where to insert loads and stores.


=====
note
=====
Need to solve two problems for inserting stores:
1) if the live range contains a def, figure out which blocks in the LR
that def reaches

2) for those blocks that def reaches, check if the successor block is
in the LR
  2.t) if it IS in the LR, then check if it needs a load
    2.t.t) if it does need a load then insert a store
    2.t.f) if it does not need a load then no store needed
  2.f) if it is NOT in the LR then check to see if the LR is live in
  at the successor block (only occurs after a split)
    2.f.t) if it is live in at successor then insert a store
    2.f.f) if it is not live in then no store needed


=========================
performance observation
=========================
Adding a coalesce pass  actually makes the performance decrease a bit
for the ra (Chaitin) code. This is not clear why, though the amount is
so small it is probably not meaningful.

On the other hand a coalesce pass helps me a lot on the order of
40,000 operations.


=================================
next steps
Thu Aug 17 15:20:08 CDT 2006
=================================
1) look at memory usage to see where we can possible free some memory
so that we do not use so much for allocation
2) implement the optimizations of placement of loads and stores.
  + review PRE as basis for the optimization
  + need to understand when this is done in the algorithm. Chow says
  to use it in order to have a more precise measurement of the
  priority function. so perhaps we can compute it as part of computing
  loads and stores, and just mark the load or store as movable, then
  when computing priority we don't have to count the cost???
3) Implement heuristics described in Chow paper for splitting. These
should improve allocation runtime speed. Chow said they did not help
allocation quality.
4) Need a peephole optimizer to take care of ST followed by immediate
LD
5) Figure out why ra does not give correct results on fpppp and seems
to loop forever on doduc (vgjyeh.i)
6) Why does Chaitin beat me so bad? Because he selects better
variables to store or is it something else?
7) Code up an example where the graph is colorable only through a
split. basically make the graph in Fig. 8 of chow's paper.
8) Check to make sure the coalesce pass is actually working
9) Review priority functions and weights given to functions to see
that priorites are computed sensibly.

Places where I think we can improve chow:
1) he uses memory to connect live ranges after he has split them. If
there was a way to notice that a store is loaded into a register in a
successor block then we could just do a register to register copy
rather than a ST/LD.

Possible splitting heruistics
1) don't add blocks if it makes the number of forbidden colors too
great (i.e. more than 1)

=================================
First Comparison
Thu Aug 17 15:24:23 CDT 2006
=================================
First comparison with the Chaitin allocator showed that it outpeformed
my Chow allocator by anywhere from 12%-133% (1.12-2.33 times better).
Brainstormed with Tim for a while about why this was the case. The
main result we thought of was that Chaitin was using a partitioned
register set while chow used a single register set. This means that
my allocator was having a lot more interferences than ra which could
be causing a lot more spilling.  Next steps to attack:

  1) make chow allocator use partitioned register set
  2) take a more detailed look at the code to see what is causing such
  a poor allocation. One identified problem is a ST followed directly
  by a LD.
  3) implement optimized placement of loads and stores





=================================
Second Comparison 
Wed Aug 23 15:52:28 CDT 2006
=================================
After the first comparison was found to be mostly bogus, I implemented
the partitioned register set for chow. This allows, for example
doubles and integers to be stored in separate register classes so that
they do not interfere.

Having done this the comparisons began.

1) dead | valnum | lazy |cprop | coalesce | chow -p
This showed that chow improved greatly on the fmm test set. It was 6%
better on fmin and mostly < 10% worse on all the others.

Spec was a different story. Chow was still doing quite bad going
anywhere from 1% to 115% worse. The oddball was matrix300 which only
was 1% worse. At this point I noticed that there were some small (42
op) routines that were doing worse. It was because Chow's version had
an extra dead instruction. It looks like ra does something to get rid
of dead instructions on its own. I decided to put a pass of dead on to
the end to see what would happen.

2) dead | valnum | lazy |cprop | coalesce | dead | chow -p
This helped quite a bit. Fmm all went down to being pretty even with
ra.

Spec got better, but still did quite bad on all the same suspects. 99%
better was ra on fpppp. I decided to pull out the big guns and limit
basic block sizes to see how much it helped

3) dead | valnum | lazy |cprop | coalesce | dead | chow -p
To my great disappointment Fmm went to shit. Most all of the programs
jumped up to more than 10% worse. It was not good.

Spec on the other hand did much better. fpppp dropped down to only 10%
worse. The highest was tomcatv at 18% worse. 

I was very suprised that reducing the basic block size did not help
everything get better (why did it make some worse?). I thought that it
would be useful to run tomcatv with various block sizes to see how it
performed. Ran with 5..30 in increments of 5. There was a sweet spot
at 25 that it actually performed better. Aha! So there was some hope.
I then looked at another small program that was doing worse (by 7
instructions). Turns out it was because of the extra JMP added when
the blocks were cleaved. I decided to run a pass of clean after to see
if it helped.

4) dead | valnum | lazy |cprop | coalesce | dead | chow -p | clean
Jackpot. This version was better on almost all programs and only very
slightly worse on some fmm (< .01%). Clean helped a bunch. 

But then I found out that ra was counting a double as using two float
registers so my results were not as good. Now rerunning experiments.

** why do I get different results than ra on the fmin which does not
spill???


============================== 
Second comparison explained
Thu Aug 24 16:24:01 CDT 2006
============================== 
The second comparison showed the two allocators to be approximately
equal. There is a problem though with how I am using temporaries. I am
not reserving the temporaries from the genearl pool, so I am really
cheating by having three-four extra registers. Need to fix that.


============================== 
Thu Aug 24 17:44:44 CDT 2006
============================== 
Notes from the conversation with Tim:

*) To run the register allocator (ra) with a reduced number of registers
use the following flags:
  -r[num] #number of registers
  -q      #"quality check" - make sure the number of registers will
          #work with the code(check the min number needed in the code)

*) Look at preston's thesis to see if you like the style of the literate
programming. Consider using nuweb for writing your thesis.

*) look at the code to make sure that it is doing what you want it to
do. The biggest challenge you will face in your experiments is
convincing people that you have implemented a chow allocator. And
not just any chow allocator, but one of decent quality. The best way
to to this is to come up with examples that show you are performing
like you would expect a chow allocator to perform. Take figures from
chow's paper and show how your allocator works just like the
examples in chow's paper says.  
  
  *) splitting example - can only color by splitting
  *) priority function example - should give higher priority to live
     range that you think 
  *) 
You can have a whole chapter in your thesis that shows these
examples along with links to your code that shows how you really did
implement chow.

*) Gather numbers on how often splitting helps you. We would like to
know when you split a live range whether you end up being able to
color part of it when you would have had to spill the entire thing if
you had not split.

*) Crank down the number of registers, try 16, 8 and see how the
algorithms perform.

*) Document your allocation parameters. We really need to have 4-5
params to have a decent search space. Better would be 6-7. Waterman
had 7 for his study of loop unrolling. So far we only have a couple
  1) basic block length
  2) priority function
  3) split small priority live ranges
  4) number of temporary register -- why would you want to reserve
     more?
  5) give clustered live ranges lower priority

  // these seem like performance improvements, not sure they should be
  // parameters
  6) select forbidden color from neighbor
  7) optimize load store placement
*) Research hard what improvements have been made to the chow
allocator. It is important that you find everything since missing a
reference could lead to people dismissing your work.

*) Read Waterman's study of loop unrolling. You will probably want to
use the same methodolgy in your adaptive chow allocator.


PLAN:
0) Write up a summary of the work you have done so far. Describe your
allocator and the choices you had to make. Also take the time to
document the allocation parameters. Look at preston's thesis and
literate programming.

1) Change your code to reserve registers for dealing with spilt code.
Now you cheat by assuming you have the correct number of registers
reserved, but this is not fair. You must reserve them from your
general pool.

2) Rerun the numbers to see how the allocators compare. Crank down the
number of registers and run those numbers as well. Gather the
statistics on how much splitting helps you.

3) Write the small code examples that mimic figures in chows paper and
shows that your allocator does what chow says.

4) Search the literature for how people have improved the chow
allocator.

5) Read Waterman's loop unrolling study

============================== 
Improvements to chow
Thu Aug 24 17:46:52 CDT 2006
============================== 
1) When we are splitting I think that it is possible that we could add
a bunch of basic blocks that are useless. When splitting we start at a
def and then do a bfs search along our successors, adding blocks as
we go. The problem is that if we never get to another use then all
those blocks we added were useless. They should not be part of the
live range since they contain no uses. Not sure if this is part of the
algorithm as specified by chow, or if it even crops up in any of our
tests.

2) One possible way to do coalescing might be to split the block at a
register to register copy and then not count that copy as an
interference. It would be cool to implement this and see if it works
and also to check to see if it would do some chaitain style
coalescing. Although to coalesce we would then need to find live
ranges that only interfere with a copy and say they are the same live
range. Merging live ranges would actually be a pretty simple operation
in chow I would think amounting to basically concatenating the
bb_lists.

3) Look for live ranges that have been split and then both parts 
assigned a register. You might have a case where you have a store and
then a load in a direct successor where the live range is split. In
this case you could replace it with a register to register copy
instead of the load/store. Implementing this would perhaps be tricky
because you would need to know that both are assigned a color and then
delete the store you inserted and replace it with a copy.


============================== 
Questions to answer
Tue Jan  9 10:32:27 CST 2007
============================== 
1) Chow claims that "splitting and spilling will most likely occur on
low priority live ranges"(pg. 515). Verify that this is the case.

2) Chow claims that using clustering as part of the metric for
computing priority would not make much of a difference, espically when
the number of registers is large (pg 513). Check to see if this is
true.

=================================
List of experiments
Tue Jan  9 10:59:25 CST 2007
Thu Aug 17 15:20:46 CDT 2006
=================================
+ Crank the size of a basic block down to 1 and compare the allocation
with Chaitin

+ Try inverting priority so that instead of allocating the most
beneficial live ranges to registers we allocate the most costly to
spill.

=================================
Problem running st
Tue Jan  9 15:47:31 CST 2007
=================================
The stats collecting script st does not work properly on my mac. When
it trys to link the files together it gets an error:

  g77 *.o -o main  /home/compiler/installed/i2c/libi2c.a \
    /home/compiler/tools/cache/libcachesim.a 
  /usr/bin/ld: Undefined symbols:
  _fprintf$LDBLStub
  collect2: ld returned 1 exit status
It looks from the web like this is a problem with using fortran and
gcc togeher. Just have to run stats on godzilla from now on.


=================================
How to deal with temporary registers for JSR/FRAME ops
Notes from a converstation with Tim.
Wed Jan 10 15:23:29 CST 2007
=================================
I am trying to fix my allocator to be realistic and faithful to Chow's
implementation. I need to reserve a few registers in order to deal
with temporary values that are spilled. Right now I am pulling
temporary registers out of thin air. 

Chow says in his paper that he reserves 4 registers for the later code
generation phase. It is not clear why he needs four. Here is one
guess: look at the instruction

ADD X,Y => Z

Now if we are spilling X and Y we generate code like this

  LD R1,R2 => R3
  LD R1,R2 => R4
  ADD R3,R4 => R3
  ST R1,R2,R3

Here, R1 and R2 are base and offset registers. The instructions for
putting the correct values in those registers are omitted. We assume
Chow has an architecture like this so he has to reserve the four
registers. We can get by with only three since we do not need an
offset register, but can use an immediate value instead. One register
for the base value (frame pointer), one for the first operand and one
for the second operand.

Now because of the architecture of iloc we have a problem with the
FRAME and JSR instructions. Iloc assumes that all parameters to
functions are passed in registers. This means that we require the
number of registers to be at least as many as the number of parameters
passed to any function in the code. So there are two cases to check

1) There is a function which takes more parameters than k - the number
of machine registers. In this case we exit with an error and say the
allocation is impossible.

2) No function takes more than k registers. In this case we can
allocate the code. A problem arises in the rewriting phase when there
are more than two unallocated parameters in the function call. If this
happens then we will run out of reserved registers, since we only
reserved enough for the normal three address instruction. In order to
solve this problem here is what we do. Look at this example in which
X,Y,Z are not allocated registers. Assume five registers total.

  JSR X,Y,Z

We would generate code like this
  LD R1,R2 => R3    #for X
  LD R1,R2 => R4    #for Y
at this point we are stuck for Z since there are no more reserved
registers. We get around this by using the following algorithm:

  1) Walk instruction from Left to Right examining all registers
  2) If a register is unallocated then try to grab a reserved register
  3) If a reserved register is available generate the LD
  4) If a reserved register is not available make sure we are on a
  JSR/FRAME instruction.
  5) Spill a register that is not used in the instruction and use that
  for a temporary register.
  6) Load the spilled value back into the temp register at the latest
  possible time. This is either
    a) at its first use in the remainder of the basic block
    b) at the end of the basic block (here we could actually do better
    and look for the first use along the paths leading from this
    block, but we just load at the basic block for now and we can go
    back and make it better at some later time).

Using that algorithm the code would be rewritten like:

  #assume R5 is in use here
  LD R1,R2 => R3    #for X
  LD R1,R2 => R4    #for Y
  ST R1,R2,R5       #store the value in R5 so we can use it
  LD R1,R2 => R5
  JSR R3,R4,R5
  #reload R5 at earliest opportunity

Fairness discussion:
We need to make sure what we are doing is fair to Chow. He was not
expecting this kind of instruction (with more than two operands) so we
have to do what seems right. The method proposed will add a few extra
LD and ST operations, but they are necessary for corectness. Chaitin
will have to do the same thing in order to execute the iloc code so
nobody gets an unfair advantage. Chow is at a bit of a disadvantage
since when we spill we have to reload at some point that may not be
the best (for example we may have to reload at the end of the basic
block but the next use could be much farther along). Chaitin will not
have this problem because he will be spilling globally and therefore
will not reload the register until it is needed at the next use.

=================================
Example of why pre-coloing for machine registers can make code
uncolorable.
Wed Jan 10 16:14:34 CST 2007
=================================
When you pre-color virtual registers to correspond to machine
registers, for example to make the calling convention work out for the
parameters that are passed in registers, you can run into a problem
that would make your code uncolorable. Look at this

         a <- 
         b <- 
      /       \
     /         \
  jsr a b     jsr b a


If we pre-color to match the required machine registers then we can
not color this code since we require a and b to be in different colors
on different sides of the branch. We get around this by inserting
copies before the jsr.
         a <- 
         b <- 
      /       \
     /         \
  y <- a      y <- b
  z <- b      z <- a
  jsr y z     jsr y z

George and Appel found this problem because of a bug in thier compiler
(according to tim) and were getting uncolorable graphs after
coalescing. They invented iterated coalescing in order to get around
it by doing a round of coalescing and the backing off if the graph
became uncolorable.



========================================================
One example of what better tmp asssignment should fix
Fri Jan 19 11:27:22 CST 2007
========================================================
In simp.i we see the following code

_main:	0	FRAME	36 => r555 r1  [ i i ] 	# function prologue
	0	iSSTor	@SPILL_1_1 4 12 r555 r1 
	3	iLDI	1 => r3 
	3	i2i	r3 => r4 
	4	iADDI	0 r555 => r5 	# get address of main_k
	4	iLDI	0 => r6 
	4	iSSTor	@main_k_0 4 0 r5 r6 
	7	i2i	r4 => r7 
	7	iLDI	0 => r2 
	0	iSSTor	@SPILL_7_7 4 16 r555 r2 
	0	iSLDor	@SPILL_7_7 4 16 r555 => r1 
	7	iCMPne	r7 r1 => r1 
	0	iSSTor	@SPILL_8_8 4 20 r555 r1 
	0	iSLDor	@SPILL_8_8 4 20 r555 => r1 
	7	BR	L1_main L4_main r1 

The store/load in the middle and end should not exist. we are storing
and then loading from the same location. if we know we have that lr in
a register there is no need for the load to exist.

========================================================
Problem With Splitting Algorithm
Fri Jan 26 11:30:37 CST 2007
========================================================
it seems that the splitting algorithm can add live units to the split
live range even when there is no point. we split the live range by
looking for a place where it starts with a def or a use and then do a
bfs of the nodes in the origlr from there adding any node that does
not fill up the forbidden register set. now suppose that we don't get
to another use of the live range in any block that we add, this means
that if we allocate this split live range it could tie up all those
blocks even though it serves no purpose to have that register tied up
since there are no uses beyond the first.

The solution may be this:
1) run split as normal
2) when finished then check the leaves of the live range. walk up the
leaves tword the root. remove any blocks along the way that are
present before the first use is encountered. this should keep only the
blocks that are "useful" in the live range. (draw a picture it will
help)


========================================================
Issue with tomcatv saveFP
Mon Jan 29 18:23:08 CST 2007
========================================================
There seems to be some issue with mixing code compiled with g77 and
gcc4. You end up with these link errors for function saveFP. This
makes it look as though tomcatv fails, but actually it is just a link
error. It may be possible to fix the problem by using gfortran, but
that needs to be installed.

I solved the problem as follows:
1) install gfortran from the mac hpc site
2) modify /home/compiler/tools/ctest/test.script and replace all
instances of g77 with gfortran.

At this point quick tests were passing except for tomcatv, which was
having a problem with the unresolved symbol _exit_. Well tomcatv.i was
calling exit for some reason (tomcatv.f does not) with a JSR so I just
deleted the line that does the JSR. That seemed to make the tests
pass.

now main.f in fpppp gets a type conversion error :\


========================================================
Cexam Question
Tue Jan 30 17:24:25 CST 2007
========================================================
Q: So should you do register allocation before scheduling, or after
scheduling?

A: Both!
The generally accpeted way to do scheduling and register allocation is
to first do a round of scheduling over a large namespace, this allows
you to rename variables to avoid anti-dependencies (WAR). In this
round of scheduling you want to not schedule to make register pressure
too high. (why?) scheduling changes the live ranges so that a variable
can be live for much longer than it needs to be. Stretching out a
bunch of live ranges makes you have to spill more.

Next you do a register allocation. This may require you to insert
spill code. This will mess with the previous schedule. Hopefully you
should be able to schedule since register pressure was taken into
consideration in the first round of scheduling.

Finally you do another round of scheduling to fix up the schedule for
any loads or stores you had to insert. The scheduler will not be able
to move code around so much this time since the namespace is fixed.


========================================================
Comp512 Notes
========================================================
possible choices for optimizations:
  DVNT
  Balanced Tree expressions - Kathryn Mckinely
  Instruction Scheduler - Shilke forward/back
the three lies - modula 3 - powell
pldi 2001 - pointer disambiguation good paper with study of ms office
john lu - register promotion in c programs

========================================================
Placement of Loads and Stores
Wed Jan 31 23:20:24 CST 2007
========================================================
I think Chow does not state preciesly how this should be computed. He
says to see if a block needs a node to check to see if it has a
predecessor that is not in the same live range. If there exists such a
predecessor then look at the block to see if it has a use
before a def, if so then put a load in. 

But this is no good because there may be no use in this block which is
the entry point, but there is a use somewhere down the line. So really
I would think that you want to check whether the variable is live out
from the entry point and if so put in a load. But even this is not
enough, since you could have a pred that is not in the live range but
there is no def along that pred. I think this would only happen in
case of an uninitalized variable. Checking liveout on the pred does
not help since it could have a use somewhere in our live range. What
we would really like to see is if there is any definition coming along
that edge. We can perhaps do this by checking for a phi-node for this
live range in that node and seeing if the path coming into the
phi-node from that pred is uninitalized. If so then the load is not
needed for that pred.

This all came about when implementing optimized placement of loads and
stores. I was moving the loads and stores onto edges, but never
actually moving them into blocks (just for testing) and I noticed that
some of the benchmarks ran correctly. This means those loads and
stores were pointless. This lead to the discovery that a live range
was saying it needed a load at the very first block of its live range
since it had a predecessor not in the live range.  (fmin.i lr:55_55)


========================================================
Chow's Splitting Algorithm
Thu Feb  1 13:45:58 CST 2007
========================================================
The problem with Chow's splitting algorithm is that it is not
agressive engouh. This means it does not try to squeeze as much
register use as possible out of the code. 

Two improvements to splitting would be:

1) Search the live range up predecessors and down successors at the
same time. This would increase the size of the live range and let you
keep more values in a register. One problem with this is that you can
end up getting a live range that contains a bunch of uses which may
not be very interesting to keep in a live range. Look at this code


                  z               z
                  x <-            x <-
                    \             /
                     \           /
                      \         /
                       \       /
                        \     /
                         \   /
                           x <-  (A)
                           |
                           |
                           |
                           |
                            <- x y
                            <- x y
                            <- x y
                              
If we search down the graph from node A we can get the uses of x
below. If we search up and down we may add the defs of x above first.
Assume both z and y are assigned registers, then we can only get
either the uses or the defs, but not both. Getting only the defs here
would mean a lot more loads and stores overall.


2) Search agressively for the uses and only add stores when it is not
going to cause a problem. The idea would be that starting with a def
we would like to connect up to as many uses as possible. We can also
modify this to use some kind of cost function to decide whether or not
we should be adding a block. There might be room for adaptive
compiling in the cost function. Another problem is this graph:


                            x <- (A)
                             /\
                            /  \
                           /    \
                          /      \
                    (B) x <-     |
                        y        /
                          \     /
                           \   /
                            \ /
                          <- x  (C)
                             z

If we get the live range AC then we need 1 store (in B) and one load
(in C). But if we get AB then we need two stores (in A and B) and one
load (in C)... So obviously there is room for improvement in the
simple algorithm of breadth first search.

The splitting algorithm is an obvious place for improving chow.
Perhaps people did not care before because they just wanted somethiing
quick and dirty, but I care. I want a really good allocation.


========================================================
Thesis contents
Thu Feb  1 13:45:58 CST 2007
========================================================
In my thesis I should have the flow of
1) chow's algorithm as described in the paper
2) practicle engineering improvements to chow
3) the adaptive chow algorithm


========================================================
Debugging Tip
Fri Feb  9 11:24:37 CST 2007
========================================================
When you see strange things happening such as values appearing to
change on random instructions then you need to make sure that your
stack is in order. This was the cause of a "hard to find" bug I
introduced when implementing MoveLoadsAndStores(). I was rewriting the
frame pointer before moving loads and stores which means that any new
spills were not getting the correct amount of stack space. I needed to
rewrite the frame op *after* moving loads and stores.


========================================================
Chow's version of MoveLoadsAndStores()
Mon Feb 12 15:43:14 CST 2007
========================================================
Chow says that you should only move loads when you have at least one
predecessor that is part of your live range. Similarly, you should
only move stores when have at least one successor that is part of your
live range. This means that a situation like


 ST X  (A)
  |
  |
  v
 LD X  (B)

Where A,B are different live ranges will not move the loads and
stores. This is correct (otherwise you would load X before the store
of X). However you miss an opportunity where you can do a register to
register copy in the different live ranges. This is what we should be
doing.

Our engineering improvment will be to find this situation where two
live ranges are connected by a ST --> LD pair and instead insert a
register to register copy.

What we need to do:
1) decide how to indicate which version of moving loads/stores we
should use

2) for chow style don't move loads and stores that are in live ranges
that have no preds that are not in the live range

3) moves for other loads/stores can be done as normal

4) in the MoveLoadsAndStores() function in chow.c we should detect
when we have a load/store on the same edge and insert a register copy
instead.

========================================================
Bug in EnhancedCodeMotion
Tue Feb 20 17:36:37 CST 2007
========================================================
I implemented the enhanced version of moving loads and stores as
described above and ran into a problem. I was getting incorrect
results on some codes. The problem was that I was deleting the load
and store when I replaced with a copy. I needed to keep the store
because there was a load later on that expected the value to be in
memory and it was not there since I had deleted the store. That can
happen if the live range looks like this


                LABEL A:
                  LD x
                  .. <- x
                  x <- ..
                  ST x
                    |
                    |
                    v
                LABEL B:
                  LD x
                  .. <- x
                  GOTO LABEL A

Here we would see the store and load for x and then delete it and
replace it with a copy. This is no good though because we load the
value at the top of block A and it will not have the correct value if
we delete the store. We can solve this by inserting the copy, deleting
the load but keeping the store.


========================================================
Another Bug in EnhancedCodeMotion
Fri Mar  2 10:05:08 CST 2007
========================================================
The order in which copy instructions were inserted was causing a
problem. 

There were two instances where this was causing a problem,
either we had a directly cyclical copy

(I)
x => y
y => x

which is fairly easy to detect, or a chain of copies like

(II)
x => y
y => z


we also saw this cycle which is a little harder to detect

(III)
x => y
y => z
z => x

In cases (II),(III) there is no ordering of the copies that will
preserve the meaning of the code (that it had in terms of load
stores). This is because we must always write at least one value
before it is used. This could be prevented by using temporaries, but
did not spend the time to implement it. Instead we detect this case
and revert to just insterting loads and stores instead of inserting
any copies. We could also improve by inserting load stores only for
the registers involved in a cyclic copy.

Case (I) can be solved by ordering the copies so that values are used
before they get overwritten. In this case we would order y => z before
x => y.


========================================================
Rematerialization
Wed Mar 21 11:56:28 CDT 2007
========================================================
So the majority of this entry was mostly a bunch of random jibberish.
I have kept it around in case it helps jog my memory at some point.
The "final" solution is right below

The core observation is that even if we mark part of the live range as
rematerializable we have to keep the stores at the live range
boundaries and if it is spilled. This is true because we don't know if
the other live range gets split, gets a register or gets spilled. A
simple copy between the live ranges is not enough because either one
may be split and then the non-remat live range will be expecting the
value in the home location so the remat live range must store it
there. The way we handle this is to 

  1) split the live ranges during live range creation
  2) allocate as normal
  3) if we allocate a liverange that is rematerailizable then
      use loadI instead of load to load values
      insert all stores as normal
     if we spill a liverange that is rematerializable then
      use loadI instead of load to load values
      insert all stores as normal
    (its the same in both cases, but the loads in case one happen at
    the live range boundaries and in case two it is interal to the
    live range)
  4) after allocation is complete run a dead store elimination pass to
  get rid of useless stores. these may happen if the remat is spilled.
  not all of the stores will reach a use and they can be dropped.
    

--------------------------OLD JUNK-----------------------------------
In order to implement rematerialization in Chow we need to solve a few
problems

  1) Finding the values which can be rematerialized.
  SOL: this can be done using the standard SSC algorithm

  2) Building initial live ranges. We need to be able to separate the
  parts of the live range which are rematerializable from those which
  can not be rematerialized.

  3) Allocating the split live range without incurring performance
  overhead. There are a few cases to consider:
    * Both live ranges are given a register
      - need a register to register copy, or biased coloring. r2r can
        be done because there is no need to store... unless it reaches
        another live range out the other side.
    * Only rematerializable is given a register
      - need a true store at end of allocated live range, or after its
        first definition. Just need to make sure it is stored for
        later use.
    * Only non-rematerializable is given a register
      - no store, load anywhere in the non-allocated live range
      - the non-allocated should use loadI to load the value on the
        edge that comes from the rematerialiazable lr
    * Neither are given a register
      - need to store rematerializable lr after its first def so a
        later load will have access to it.
      - the non-allocated should use loadI to load the value


  options
  1) split live ranges initially and note that liverange remat was
  splitfrom liverange noremat
    PROBLEMS:

  2) keep the live range joined at first. note in the live range that
  it can be split into a remat part. when splitting the live range,
  first just split the remat part, clear the flag and then check if
  more splitting is needed
    PROBLEMS:
    + how do we keep track of the part that is remat?
    + once they are split how do handle stores/loads at the new live
      range boundaries

  3) split live ranges initially and insert a copy from remat to
  non-remat.
    PROBLEMS:
    + inserting a copy means that the live ranges will interfere and
    never be asssigned to the same register.

  PLAN:
  Split live ranges initially. Do not bother putting in the copy as
  that is not enough guarantee that the home location will stay
  updated. The non-remat live range my be further split and one of
  those may require a load.

  When spilling a remat live range we can load always by doing the
  rematerialization. Stores are done normally in the remat live range.
  Use enhanced code motion to convert LOAD/STORE pairs to copies

  Once spilling has been completed look for dead stores. In fact we
  can use dead to do this for us.
--------------------------OLD JUNK-----------------------------------

=======================================================
Copy Coalescing in Chow
Wed Mar 21 22:38:15 CDT 2007
========================================================
I can do copy coalescing in chow. Here is how:

  //Walk the code 
  for each copy operation (a <- b)
    if  1) a.bb_list INTERSECT b.bb_list == the current block
       AND
        2) b.last_use == the current operation 
    then
    //can coalesce
    choose a (arbitrarly) to be the coalesced live range
    a.bb_list = a.bb_list UNION b.bb_list (vector set - O(n))
    a.fear_list = a.fear_list UNION b.fear_list (stl set - O(n))
    a.units = a.units UNION (b.units - unit for current block) (stl list -O(n))
    a.unit_for_this_block.last_use = max(a.last_use, b.last_use)

    //the values in the live units should be valid since we have done
    //no splitting yet there should not be any loads/stores necessary
    //at live range boundaries. The exception would be an uninitalized
    //value which could cause a live range to need a load at its first
    //use


========================================================
Enhanced Code Motion Observations
Fri Mar 23 00:09:43 CDT 2007
========================================================
So it turns out that EnhancedCodeMotion may not be so "enhanced". The
idea was that movement of loads and stores would always occur. Chow
says move a load up if there is at least a predecessor in the live
range so that you get some benefit by having a path where the load
does not need to occur. 

I changed that to say always move the load up. The intent was to
capture situations where we have a load and store to same location. We
would not catch the case where there is only one predecessor that
contains a store.

Now we have to leave the stores in and we can only replace the loads.
This is necessary for corectness. Running dead can make it profitable.
One curious thing is that enhanced code motions sometimes makes the
execution worse. I am not sure why but I suspect it is because of the
extra control flow (ecm always splits edges). We rely on clean to join
edges as necessary.

Turns out the enhanced is only profitable sometimes. Check out rkfs
for an example of where it hurts.

*EXPLORE MORE*
So changeing ECM to only move the load/store onto an edge is when
there are lrPreds (for sure profitable) or the pred count is 1 which
is to catch the specific case we are after.

        bool moveit =((PARAM_EnhancedCodeMotion 
                        && unit->block->pred_count == 1) 
                     || lrPreds > 0);

This allowed rkfs to actually change to be profitable under ECM.
However urand lost its profit to be equal with normal code motion. So
obviously this has an effect and we should look at how this parameter
effects other benchmarks.

