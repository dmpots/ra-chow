=====
note
=====
question:

does splitting critical edges change the splitting of live ranges? for
example look at fmin.i where splitting critical edges makes chow fail
an insertion on multiple defs..

it seems that splitting critical edges can change the number of
interferences in a live range. This happens when the block for the 
split critical edge is added to a live range to extend its range. This
will happen when the live range is split and adds the extra block even
though it is not needed.

L1:
  z
  BRANCH L2 L3
  
L2:
  y
  GOTO L3

L3:
  y
  x
  END

with split critical edges in this case both x and z extend to the
dummy block L4, which increases their interferences. this can happen
with bad splitting (by adding a block when there is no subsequent use
(z) and adding a block before the first use (x)

L1:
  z
  BRANCH L2 L4
  
L2:
  y
  GOTO L3

L4:
  z
  x
  GOTO L3

L3:
  y
  x


=====
note
=====
it makes a big difference where you choose your split point,
otherwise you can end up with a bunch of live units with no uses and
no defs and the whole live range contains these useless units. i think
that is the cause of the "peeling" splitting we saw where it would
peel off on of the live units each time it would split, but that would
not help since it is a useless live unit


=====
note
=====
question:
why are we not putting the loads and stores in the right place? we are
calculating stores by looking at the uses that each def reaches. if it
reaches a use in another live range then we add a store. if it reaches
a use in the same live range that needs a load we add a store.

we compute loads by looking at the predecessor blocks. if the
predecessor is in another live range then we insert a load.

answer:
phi nodes were getting in the way. if a def reaches a use that is a
phi-node it is not a real use. we need to look at the uses that the
phi-node def reaches as well in order to find all the nodes that def
actually reaches.

=====
note
=====
speed up attemtps: 
 + use a set to for interferece "list" so that adding unique values is
 efficent (log n)

 + choose the starting point for the split much better
   - only split starting with a def or a use
   - split starting with an entry point if possible

 + a live range is uncolorable if all the live units where it actually
 has a use or a def have no available registers

 + only need to update interferences for the new and orig lr and those
 live ranges that they interfered with. can be done efficently by
 iterating over the origlr interferences and seeing what they now
 interfere with


=====
note
=====
observation:

it seems that the splitting algorithm can add live units to the split
live range even when there is no point. we split the live range by
looking for a place where it starts with a def or a use and then do a
bfs of the nodes in the origlr from there adding any node that does
not fill up the forbidden register set. now suppose that we don't get
to another use of the live range in any block that we add, this means
that if we allocate this split live range it could tie up all those
blocks even though it serves no purpose to have that register tied up
since there are no uses beyond the first.

I suspect that the priority function is designed to prevent this from
happening, but it is something to watch for.


=====
note
=====
question:

Would it be beneficial to split the BB at register to register copies?



=====
note
=====
Had a problem where a load was inserted for a live range because it
had a predecessor that was not in the live range, but no store was
inserted in any of the other blocks in the live range. Turns out the
load was requested because it was used in a phi-node, but no store was
generated because we were not counting phi-node uses. 

not sure how exactly this should be handeled. need to better figure
out where to insert loads and stores.


=====
note
=====
Need to solve two problems for inserting stores:
1) if the live range contains a def, figure out which blocks in the LR
that def reaches

2) for those blocks that def reaches, check if the successor block is
in the LR
  2.t) if it IS in the LR, then check if it needs a load
    2.t.t) if it does need a load then insert a store
    2.t.f) if it does not need a load then no store needed
  2.f) if it is NOT in the LR then check to see if the LR is live in
  at the successor block (only occurs after a split)
    2.f.t) if it is live in at successor then insert a store
    2.f.f) if it is not live in then no store needed


=========================
performance observation
=========================
Adding a coalesce pass  actually makes the performance decrease a bit
for the ra (Chaitin) code. This is not clear why, though the amount is
so small it is probably not meaningful.

On the other hand a coalesce pass helps me a lot on the order of
40,000 operations.


=================================
next steps
Thu Aug 17 15:20:08 CDT 2006
=================================
1) look at memory usage to see where we can possible free some memory
so that we do not use so much for allocation
2) implement the optimizations of placement of loads and stores.
  + review PRE as basis for the optimization
  + need to understand when this is done in the algorithm. Chow says
  to use it in order to have a more precise measurement of the
  priority function. so perhaps we can compute it as part of computing
  loads and stores, and just mark the load or store as movable, then
  when computing priority we don't have to count the cost???
3) Implement heuristics described in Chow paper for splitting. These
should improve allocation runtime speed. Chow said they did not help
allocation quality.
4) Need a peephole optimizer to take care of ST followed by immediate
LD
5) Figure out why ra does not give correct results on fpppp and seems
to loop forever on doduc (vgjyeh.i)
6) Why does Chaitin beat me so bad? Because he selects better
variables to store or is it something else?
7) Code up an example where the graph is colorable only through a
split. basically make the graph in Fig. 8 of chow's paper.
8) Check to make sure the coalesce pass is actually working
9) Review priority functions and weights given to functions to see
that priorites are computed sensibly.

Places where I think we can improve chow:
1) he uses memory to connect live ranges after he has split them. If
there was a way to notice that a store is loaded into a register in a
successor block then we could just do a register to register copy
rather than a ST/LD.

Possible splitting heruistics
1) don't add blocks if it makes the number of forbidden colors too
great (i.e. more than 1)

=================================
First Comparison
Thu Aug 17 15:24:23 CDT 2006
=================================
First comparison with the Chaitin allocator showed that it outpeformed
my Chow allocator by anywhere from 12%-133% (1.12-2.33 times better).
Brainstormed with Tim for a while about why this was the case. The
main result we thought of was that Chaitin was using a partitioned
register set while chow used a single register set. This means that
my allocator was having a lot more interferences than ra which could
be causing a lot more spilling.  Next steps to attack:

  1) make chow allocator use partitioned register set
  2) take a more detailed look at the code to see what is causing such
  a poor allocation. One identified problem is a ST followed directly
  by a LD.
  3) implement optimized placement of loads and stores





=================================
Second Comparison 
Wed Aug 23 15:52:28 CDT 2006
=================================
After the first comparison was found to be mostly bogus, I implemented
the partitioned register set for chow. This allows, for example
doubles and integers to be stored in separate register classes so that
they do not interfere.

Having done this the comparisons began.

1) dead | valnum | lazy |cprop | coalesce | chow -p
This showed that chow improved greatly on the fmm test set. It was 6%
better on fmin and mostly < 10% worse on all the others.

Spec was a different story. Chow was still doing quite bad going
anywhere from 1% to 115% worse. The oddball was matrix300 which only
was 1% worse. At this point I noticed that there were some small (42
op) routines that were doing worse. It was because Chow's version had
an extra dead instruction. It looks like ra does something to get rid
of dead instructions on its own. I decided to put a pass of dead on to
the end to see what would happen.

2) dead | valnum | lazy |cprop | coalesce | dead | chow -p
This helped quite a bit. Fmm all went down to being pretty even with
ra.

Spec got better, but still did quite bad on all the same suspects. 99%
better was ra on fpppp. I decided to pull out the big guns and limit
basic block sizes to see how much it helped

3) dead | valnum | lazy |cprop | coalesce | dead | chow -p
To my great disappointment Fmm went to shit. Most all of the programs
jumped up to more than 10% worse. It was not good.

Spec on the other hand did much better. fpppp dropped down to only 10%
worse. The highest was tomcatv at 18% worse. 

I was very suprised that reducing the basic block size did not help
everything get better (why did it make some worse?). I thought that it
would be useful to run tomcatv with various block sizes to see how it
performed. Ran with 5..30 in increments of 5. There was a sweet spot
at 25 that it actually performed better. Aha! So there was some hope.
I then looked at another small program that was doing worse (by 7
instructions). Turns out it was because of the extra JMP added when
the blocks were cleaved. I decided to run a pass of clean after to see
if it helped.

4) dead | valnum | lazy |cprop | coalesce | dead | chow -p | clean
Jackpot. This version was better on almost all programs and only very
slightly worse on some fmm (< .01%). Clean helped a bunch. 

But then I found out that ra was counting a double as using two float
registers so my results were not as good. Now rerunning experiments.

** why do I get different results than ra on the fmin which does not
spill???


============================== 
Second comparison explained
Thu Aug 24 16:24:01 CDT 2006
============================== 
The second comparison showed the two allocators to be approximately
equal. There is a problem though with how I am using temporaries. I am
not reserving the temporaries from the genearl pool, so I am really
cheating by having three-four extra registers. Need to fix that.


============================== 
Thu Aug 24 17:44:44 CDT 2006
============================== 
Notes from the conversation with Tim:

*) To run the register allocator (ra) with a reduced number of registers
use the following flags:
  -r[num] #number of registers
  -q      #"quality check" - make sure the number of registers will
          #work with the code(check the min number needed in the code)

*) Look at preston's thesis to see if you like the style of the literate
programming. Consider using nuweb for writing your thesis.

*) look at the code to make sure that it is doing what you want it to
do. The biggest challenge you will face in your experiments is
convincing people that you have implemented a chow allocator. And
not just any chow allocator, but one of decent quality. The best way
to to this is to come up with examples that show you are performing
like you would expect a chow allocator to perform. Take figures from
chow's paper and show how your allocator works just like the
examples in chow's paper says.  
  
  *) splitting example - can only color by splitting
  *) priority function example - should give higher priority to live
     range that you think 
  *) 
You can have a whole chapter in your thesis that shows these
examples along with links to your code that shows how you really did
implement chow.

*) Gather numbers on how often splitting helps you. We would like to
know when you split a live range whether you end up being able to
color part of it when you would have had to spill the entire thing if
you had not split.

*) Crank down the number of registers, try 16, 8 and see how the
algorithms perform.

*) Document your allocation parameters. We really need to have 4-5
params to have a decent search space. Better would be 6-7. Waterman
had 7 for his study of loop unrolling. So far we only have a couple
  1) basic block length
  2) priority function
  3) split small priority live ranges
  4) number of temporary register -- why would you want to reserve
     more?
  5) give clustered live ranges lower priority

  // these seem like performance improvements, not sure they should be
  // parameters
  6) select forbidden color from neighbor
  7) optimize load store placement
*) Research hard what improvements have been made to the chow
allocator. It is important that you find everything since missing a
reference could lead to people dismissing your work.

*) Read Waterman's study of loop unrolling. You will probably want to
use the same methodolgy in your adaptive chow allocator.


PLAN:
0) Write up a summary of the work you have done so far. Describe your
allocator and the choices you had to make. Also take the time to
document the allocation parameters. Look at preston's thesis and
literate programming.

1) Change your code to reserve registers for dealing with spilt code.
Now you cheat by assuming you have the correct number of registers
reserved, but this is not fair. You must reserve them from your
general pool.

2) Rerun the numbers to see how the allocators compare. Crank down the
number of registers and run those numbers as well. Gather the
statistics on how much splitting helps you.

3) Write the small code examples that mimic figures in chows paper and
shows that your allocator does what chow says.

4) Search the literature for how people have improved the chow
allocator.

5) Read Waterman's loop unrolling study

============================== 
Improvements to chow
Thu Aug 24 17:46:52 CDT 2006
============================== 
1) When we are splitting I think that it is possible that we could add
a bunch of basic blocks that are useless. When splitting we start at a
def and then do a bfs search along our successors, adding blocks as
we go. The problem is that if we never get to another use then all
those blocks we added were useless. They should not be part of the
live range since they contain no uses. Not sure if this is part of the
algorithm as specified by chow, or if it even crops up in any of our
tests.

2) One possible way to do coalescing might be to split the block at a
register to register copy and then not count that copy as an
interference. It would be cool to implement this and see if it works
and also to check to see if it would do some chaitain style
coalescing. Although to coalesce we would then need to find live
ranges that only interfere with a copy and say they are the same live
range. Merging live ranges would actually be a pretty simple operation
in chow I would think amounting to basically concatenating the
bb_lists.

3) Look for live ranges that have been split and then both parts 
assigned a register. You might have a case where you have a store and
then a load in a direct successor where the live range is split. In
this case you could replace it with a register to register copy
instead of the load/store. Implementing this would perhaps be tricky
because you would need to know that both are assigned a color and then
delete the store you inserted and replace it with a copy.


============================== 
Questions to answer
Tue Jan  9 10:32:27 CST 2007
============================== 
1) Chow claims that "splitting and spilling will most likely occur on
low priority live ranges"(pg. 515). Verify that this is the case.

2) Chow claims that using clustering as part of the metric for
computing priority would not make much of a difference, espically when
the number of registers is large (pg 513). Check to see if this is
true.

=================================
List of experiments
Tue Jan  9 10:59:25 CST 2007
Thu Aug 17 15:20:46 CDT 2006
=================================
+ Crank the size of a basic block down to 1 and compare the allocation
with Chaitin

+ Try inverting priority so that instead of allocating the most
beneficial live ranges to registers we allocate the most costly to
spill.

=================================
Problem running st
Tue Jan  9 15:47:31 CST 2007
=================================
The stats collecting script st does not work properly on my mac. When
it trys to link the files together it gets an error:

  g77 *.o -o main  /home/compiler/installed/i2c/libi2c.a \
    /home/compiler/tools/cache/libcachesim.a 
  /usr/bin/ld: Undefined symbols:
  _fprintf$LDBLStub
  collect2: ld returned 1 exit status
It looks from the web like this is a problem with using fortran and
gcc togeher. Just have to run stats on godzilla from now on.


=================================
How to deal with temporary registers for JSR/FRAME ops
Notes from a converstation with Tim.
Wed Jan 10 15:23:29 CST 2007
=================================
I am trying to fix my allocator to be realistic and faithful to Chow's
implementation. I need to reserve a few registers in order to deal
with temporary values that are spilled. Right now I am pulling
temporary registers out of thin air. 

Chow says in his paper that he reserves 4 registers for the later code
generation phase. It is not clear why he needs four. Here is one
guess: look at the instruction

ADD X,Y => Z

Now if we are spilling X and Y we generate code like this

  LD R1,R2 => R3
  LD R1,R2 => R4
  ADD R3,R4 => R3
  ST R1,R2,R3

Here, R1 and R2 are base and offset registers. The instructions for
putting the correct values in those registers are omitted. We assume
Chow has an architecture like this so he has to reserve the four
registers. We can get by with only three since we do not need an
offset register, but can use an immediate value instead. One register
for the base value (frame pointer), one for the first operand and one
for the second operand.

Now because of the architecture of iloc we have a problem with the
FRAME and JSR instructions. Iloc assumes that all parameters to
functions are passed in registers. This means that we require the
number of registers to be at least as many as the number of parameters
passed to any function in the code. So there are two cases to check

1) There is a function which takes more parameters than k - the number
of machine registers. In this case we exit with an error and say the
allocation is impossible.

2) No function takes more than k registers. In this case we can
allocate the code. A problem arises in the rewriting phase when there
are more than two unallocated parameters in the function call. If this
happens then we will run out of reserved registers, since we only
reserved enough for the normal three address instruction. In order to
solve this problem here is what we do. Look at this example in which
X,Y,Z are not allocated registers. Assume five registers total.

  JSR X,Y,Z

We would generate code like this
  LD R1,R2 => R3    #for X
  LD R1,R2 => R4    #for Y
at this point we are stuck for Z since there are no more reserved
registers. We get around this by using the following algorithm:

  1) Walk instruction from Left to Right examining all registers
  2) If a register is unallocated then try to grab a reserved register
  3) If a reserved register is available generate the LD
  4) If a reserved register is not available make sure we are on a
  JSR/FRAME instruction.
  5) Spill a register that is not used in the instruction and use that
  for a temporary register.
  6) Load the spilled value back into the temp register at the latest
  possible time. This is either
    a) at its first use in the remainder of the basic block
    b) at the end of the basic block (here we could actually do better
    and look for the first use along the paths leading from this
    block, but we just load at the basic block for now and we can go
    back and make it better at some later time).

Using that algorithm the code would be rewritten like:

  #assume R5 is in use here
  LD R1,R2 => R3    #for X
  LD R1,R2 => R4    #for Y
  ST R1,R2,R5       #store the value in R5 so we can use it
  LD R1,R2 => R5
  JSR R3,R4,R5
  #reload R5 at earliest opportunity

Fairness discussion:
We need to make sure what we are doing is fair to Chow. He was not
expecting this kind of instruction (with more than two operands) so we
have to do what seems right. The method proposed will add a few extra
LD and ST operations, but they are necessary for corectness. Chaitin
will have to do the same thing in order to execute the iloc code so
nobody gets an unfair advantage. Chow is at a bit of a disadvantage
since when we spill we have to reload at some point that may not be
the best (for example we may have to reload at the end of the basic
block but the next use could be much farther along). Chaitin will not
have this problem because he will be spilling globally and therefore
will not reload the register until it is needed at the next use.

=================================
Example of why pre-coloing for machine registers can make code
uncolorable.
Wed Jan 10 16:14:34 CST 2007
=================================
When you pre-color virtual registers to correspond to machine
registers, for example to make the calling convention work out for the
parameters that are passed in registers, you can run into a problem
that would make your code uncolorable. Look at this

         a <- 
         b <- 
      /       \
     /         \
  jsr a b     jsr b a


If we pre-color to match the required machine registers then we can
not color this code since we require a and b to be in different colors
on different sides of the branch. We get around this by inserting
copies before the jsr.
         a <- 
         b <- 
      /       \
     /         \
  y <- a      y <- b
  z <- b      z <- a
  jsr y z     jsr y z

George and Appel found this problem because of a bug in thier compiler
(according to tim) and were getting uncolorable graphs after
coalescing. They invented iterated coalescing in order to get around
it by doing a round of coalescing and the backing off if the graph
became uncolorable.



========================================================
One example of what better tmp asssignment should fix
Fri Jan 19 11:27:22 CST 2007
========================================================
In simp.i we see the following code

_main:  0 FRAME 36 => r555 r1  [ i i ]  # function prologue
  0 iSSTor  @SPILL_1_1 4 12 r555 r1 
  3 iLDI  1 => r3 
  3 i2i r3 => r4 
  4 iADDI 0 r555 => r5  # get address of main_k
  4 iLDI  0 => r6 
  4 iSSTor  @main_k_0 4 0 r5 r6 
  7 i2i r4 => r7 
  7 iLDI  0 => r2 
  0 iSSTor  @SPILL_7_7 4 16 r555 r2 
  0 iSLDor  @SPILL_7_7 4 16 r555 => r1 
  7 iCMPne  r7 r1 => r1 
  0 iSSTor  @SPILL_8_8 4 20 r555 r1 
  0 iSLDor  @SPILL_8_8 4 20 r555 => r1 
  7 BR  L1_main L4_main r1 

The store/load in the middle and end should not exist. we are storing
and then loading from the same location. if we know we have that lr in
a register there is no need for the load to exist.

========================================================
Problem With Splitting Algorithm
Fri Jan 26 11:30:37 CST 2007
========================================================
it seems that the splitting algorithm can add live units to the split
live range even when there is no point. we split the live range by
looking for a place where it starts with a def or a use and then do a
bfs of the nodes in the origlr from there adding any node that does
not fill up the forbidden register set. now suppose that we don't get
to another use of the live range in any block that we add, this means
that if we allocate this split live range it could tie up all those
blocks even though it serves no purpose to have that register tied up
since there are no uses beyond the first.

The solution may be this:
1) run split as normal
2) when finished then check the leaves of the live range. walk up the
leaves tword the root. remove any blocks along the way that are
present before the first use is encountered. this should keep only the
blocks that are "useful" in the live range. (draw a picture it will
help)


========================================================
Issue with tomcatv saveFP
Mon Jan 29 18:23:08 CST 2007
========================================================
There seems to be some issue with mixing code compiled with g77 and
gcc4. You end up with these link errors for function saveFP. This
makes it look as though tomcatv fails, but actually it is just a link
error. It may be possible to fix the problem by using gfortran, but
that needs to be installed.

I solved the problem as follows:
1) install gfortran from the mac hpc site
2) modify /home/compiler/tools/ctest/test.script and replace all
instances of g77 with gfortran.

At this point quick tests were passing except for tomcatv, which was
having a problem with the unresolved symbol _exit_. Well tomcatv.i was
calling exit for some reason (tomcatv.f does not) with a JSR so I just
deleted the line that does the JSR. That seemed to make the tests
pass.

now main.f in fpppp gets a type conversion error :\


========================================================
Cexam Question
Tue Jan 30 17:24:25 CST 2007
========================================================
Q: So should you do register allocation before scheduling, or after
scheduling?

A: Both!
The generally accpeted way to do scheduling and register allocation is
to first do a round of scheduling over a large namespace, this allows
you to rename variables to avoid anti-dependencies (WAR). In this
round of scheduling you want to not schedule to make register pressure
too high. (why?) scheduling changes the live ranges so that a variable
can be live for much longer than it needs to be. Stretching out a
bunch of live ranges makes you have to spill more.

Next you do a register allocation. This may require you to insert
spill code. This will mess with the previous schedule. Hopefully you
should be able to schedule since register pressure was taken into
consideration in the first round of scheduling.

Finally you do another round of scheduling to fix up the schedule for
any loads or stores you had to insert. The scheduler will not be able
to move code around so much this time since the namespace is fixed.


========================================================
Comp512 Notes
========================================================
possible choices for optimizations:
  DVNT
  Balanced Tree expressions - Kathryn Mckinely
  Instruction Scheduler - Shilke forward/back
the three lies - modula 3 - powell
pldi 2001 - pointer disambiguation good paper with study of ms office
john lu - register promotion in c programs

========================================================
Placement of Loads and Stores
Wed Jan 31 23:20:24 CST 2007
========================================================
I think Chow does not state preciesly how this should be computed. He
says to see if a block needs a node to check to see if it has a
predecessor that is not in the same live range. If there exists such a
predecessor then look at the block to see if it has a use
before a def, if so then put a load in. 

But this is no good because there may be no use in this block which is
the entry point, but there is a use somewhere down the line. So really
I would think that you want to check whether the variable is live out
from the entry point and if so put in a load. But even this is not
enough, since you could have a pred that is not in the live range but
there is no def along that pred. I think this would only happen in
case of an uninitalized variable. Checking liveout on the pred does
not help since it could have a use somewhere in our live range. What
we would really like to see is if there is any definition coming along
that edge. We can perhaps do this by checking for a phi-node for this
live range in that node and seeing if the path coming into the
phi-node from that pred is uninitalized. If so then the load is not
needed for that pred.

This all came about when implementing optimized placement of loads and
stores. I was moving the loads and stores onto edges, but never
actually moving them into blocks (just for testing) and I noticed that
some of the benchmarks ran correctly. This means those loads and
stores were pointless. This lead to the discovery that a live range
was saying it needed a load at the very first block of its live range
since it had a predecessor not in the live range.  (fmin.i lr:55_55)


========================================================
Chow's Splitting Algorithm
Thu Feb  1 13:45:58 CST 2007
========================================================
The problem with Chow's splitting algorithm is that it is not
agressive engouh. This means it does not try to squeeze as much
register use as possible out of the code. 

Two improvements to splitting would be:

1) Search the live range up predecessors and down successors at the
same time. This would increase the size of the live range and let you
keep more values in a register. One problem with this is that you can
end up getting a live range that contains a bunch of uses which may
not be very interesting to keep in a live range. Look at this code


                  z               z
                  x <-            x <-
                    \             /
                     \           /
                      \         /
                       \       /
                        \     /
                         \   /
                           x <-  (A)
                           |
                           |
                           |
                           |
                            <- x y
                            <- x y
                            <- x y
                              
If we search down the graph from node A we can get the uses of x
below. If we search up and down we may add the defs of x above first.
Assume both z and y are assigned registers, then we can only get
either the uses or the defs, but not both. Getting only the defs here
would mean a lot more loads and stores overall.


2) Search agressively for the uses and only add stores when it is not
going to cause a problem. The idea would be that starting with a def
we would like to connect up to as many uses as possible. We can also
modify this to use some kind of cost function to decide whether or not
we should be adding a block. There might be room for adaptive
compiling in the cost function. Another problem is this graph:


                            x <- (A)
                             /\
                            /  \
                           /    \
                          /      \
                    (B) x <-     |
                        y        /
                          \     /
                           \   /
                            \ /
                          <- x  (C)
                             z

If we get the live range AC then we need 1 store (in B) and one load
(in C). But if we get AB then we need two stores (in A and B) and one
load (in C)... So obviously there is room for improvement in the
simple algorithm of breadth first search.

The splitting algorithm is an obvious place for improving chow.
Perhaps people did not care before because they just wanted somethiing
quick and dirty, but I care. I want a really good allocation.


========================================================
Thesis contents
Thu Feb  1 13:45:58 CST 2007
========================================================
In my thesis I should have the flow of
1) chow's algorithm as described in the paper
2) practicle engineering improvements to chow
3) the adaptive chow algorithm


========================================================
Debugging Tip
Fri Feb  9 11:24:37 CST 2007
========================================================
When you see strange things happening such as values appearing to
change on random instructions then you need to make sure that your
stack is in order. This was the cause of a "hard to find" bug I
introduced when implementing MoveLoadsAndStores(). I was rewriting the
frame pointer before moving loads and stores which means that any new
spills were not getting the correct amount of stack space. I needed to
rewrite the frame op *after* moving loads and stores.


========================================================
Chow's version of MoveLoadsAndStores()
Mon Feb 12 15:43:14 CST 2007
========================================================
Chow says that you should only move loads when you have at least one
predecessor that is part of your live range. Similarly, you should
only move stores when have at least one successor that is part of your
live range. This means that a situation like


 ST X  (A)
  |
  |
  v
 LD X  (B)

Where A,B are different live ranges will not move the loads and
stores. This is correct (otherwise you would load X before the store
of X). However you miss an opportunity where you can do a register to
register copy in the different live ranges. This is what we should be
doing.

Our engineering improvment will be to find this situation where two
live ranges are connected by a ST --> LD pair and instead insert a
register to register copy.

What we need to do:
1) decide how to indicate which version of moving loads/stores we
should use

2) for chow style don't move loads and stores that are in live ranges
that have no preds that are not in the live range

3) moves for other loads/stores can be done as normal

4) in the MoveLoadsAndStores() function in chow.c we should detect
when we have a load/store on the same edge and insert a register copy
instead.

========================================================
Bug in EnhancedCodeMotion
Tue Feb 20 17:36:37 CST 2007
========================================================
I implemented the enhanced version of moving loads and stores as
described above and ran into a problem. I was getting incorrect
results on some codes. The problem was that I was deleting the load
and store when I replaced with a copy. I needed to keep the store
because there was a load later on that expected the value to be in
memory and it was not there since I had deleted the store. That can
happen if the live range looks like this


                LABEL A:
                  LD x
                  .. <- x
                  x <- ..
                  ST x
                    |
                    |
                    v
                LABEL B:
                  LD x
                  .. <- x
                  GOTO LABEL A

Here we would see the store and load for x and then delete it and
replace it with a copy. This is no good though because we load the
value at the top of block A and it will not have the correct value if
we delete the store. We can solve this by inserting the copy, deleting
the load but keeping the store.


========================================================
Another Bug in EnhancedCodeMotion
Fri Mar  2 10:05:08 CST 2007
========================================================
The order in which copy instructions were inserted was causing a
problem. 

There were two instances where this was causing a problem,
either we had a directly cyclical copy

(I)
x => y
y => x

which is fairly easy to detect, or a chain of copies like

(II)
x => y
y => z


we also saw this cycle which is a little harder to detect

(III)
x => y
y => z
z => x

In cases (I),(III) there is no ordering of the copies that will
preserve the meaning of the code (that it had in terms of load
stores). This is because we must always write at least one value
before it is used. This could be prevented by using temporaries, but
did not spend the time to implement it. Instead we detect this case
and revert to just insterting loads and stores instead of inserting
any copies. We could also improve by inserting load stores only for
the registers involved in a cyclic copy.

Case (II) can be solved by ordering the copies so that values are used
before they get overwritten. In this case we would order y => z before
x => y.


========================================================
Rematerialization
Wed Mar 21 11:56:28 CDT 2007
========================================================
So the majority of this entry was mostly a bunch of random jibberish.
I have kept it around in case it helps jog my memory at some point.
The "final" solution is right below

Briggs, Cooper, Torczan talk about
splitting live ranges by inserting a copy so that the rematerializable
can be spilled separately. For example the following code is in SSA
form


                  x <-  7          y <- ?
                    \              /
                     \            /
                      \          /
                       \        /
                        \      /
                         \   /
                       z <- phi(x,y)
                           |
                           |
                           |
                           |
                         <- z

Is converted to the form below.  A copy is inserted at (A) and the phi
node result (z) and the paramerter (y) are unioned together. The copy
is inserted because (x) can not be unioned with (z) since they have
different tags. This copy is what allows the live range to be split.
If the resulting live range will not be spilled, then they will
coalesce the copy back so that it is only one live range.

 
                  x <-  7          z <- ?
                    \              /
                     \            /
                      \          /
                       \        /
                        \      /
                (A)   z <- x  /
                         \   /
                           |
                           |
                           |
                           |
                          <- z
 
Inserting copies like this will cause problems for chow. For one thing
chow does not do copy coalescing. Another reason is that you would
have to represent the live ranges as two separate live ranges, not as
a single live range that has been split. The reason is that a basic
block can only belong to one part of the split live range not to both
parts. Tim suggested trying something like t <- x, z <- t in order to
connect the live ranges where t > #machine_regs. This might work but
you have to rely on peep to do the cleanup and may have to create new
blocks to split the copies around which would increase processing
time.

A more natural way to implement rematerialization in chow is to
leverage the splitting mechanism already built into chow. This means
that we find the tags as normal and then when building the live ranges
if we are unioning together at a phi node two live ranges that have
different tags we would instead note that the live ranges should be
split. We create the initial live range and then split out the part
that is rematerializable. We then run the allocation as normal. We
rely on dead code elimination to get rid of useless stores. Also, if
both live ranges are given a register then we replace the load,store
pair with a register to register copy (enhanced code motion).

The core observation is that even if we mark part of the live range as
rematerializable we have to keep the stores at the live range
boundaries and if it is spilled. This is true because we don't know if
the other live range gets split, gets a register or gets spilled. A
simple copy between the live ranges is not enough because either one
may be split and then the non-remat live range will be expecting the
value in the home location so the remat live range must store it
there. The way we handle this is to 

  1) split the live ranges during live range creation
  2) allocate as normal
  3) if we allocate a liverange that is rematerailizable then
      use loadI instead of load to load values
      insert all stores as normal
     if we spill a liverange that is rematerializable then
      use loadI instead of load to load values
      insert all stores as normal
    (its the same in both cases, but the loads in case one happen at
    the live range boundaries and in case two it is interal to the
    live range)
  4) after allocation is complete run a dead store elimination pass to
  get rid of useless stores. these may happen if the remat is spilled.
  not all of the stores will reach a use and they can be dropped.
    

--------------------------OLD JUNK-----------------------------------
In order to implement rematerialization in Chow we need to solve a few
problems

  1) Finding the values which can be rematerialized.
  SOL: this can be done using the standard SSC algorithm

  2) Building initial live ranges. We need to be able to separate the
  parts of the live range which are rematerializable from those which
  can not be rematerialized.

  3) Allocating the split live range without incurring performance
  overhead. There are a few cases to consider:
    * Both live ranges are given a register
      - need a register to register copy, or biased coloring. r2r can
        be done because there is no need to store... unless it reaches
        another live range out the other side.
    * Only rematerializable is given a register
      - need a true store at end of allocated live range, or after its
        first definition. Just need to make sure it is stored for
        later use.
    * Only non-rematerializable is given a register
      - no store, load anywhere in the non-allocated live range
      - the non-allocated should use loadI to load the value on the
        edge that comes from the rematerialiazable lr
    * Neither are given a register
      - need to store rematerializable lr after its first def so a
        later load will have access to it.
      - the non-allocated should use loadI to load the value


  options
  1) split live ranges initially and note that liverange remat was
  splitfrom liverange noremat
    PROBLEMS:

  2) keep the live range joined at first. note in the live range that
  it can be split into a remat part. when splitting the live range,
  first just split the remat part, clear the flag and then check if
  more splitting is needed
    PROBLEMS:
    + how do we keep track of the part that is remat?
    + once they are split how do handle stores/loads at the new live
      range boundaries

  3) split live ranges initially and insert a copy from remat to
  non-remat.
    PROBLEMS:
    + inserting a copy means that the live ranges will interfere and
    never be asssigned to the same register.

  PLAN:
  Split live ranges initially. Do not bother putting in the copy as
  that is not enough guarantee that the home location will stay
  updated. The non-remat live range my be further split and one of
  those may require a load.

  When spilling a remat live range we can load always by doing the
  rematerialization. Stores are done normally in the remat live range.
  Use enhanced code motion to convert LOAD/STORE pairs to copies

  Once spilling has been completed look for dead stores. In fact we
  can use dead to do this for us.
--------------------------OLD JUNK-----------------------------------

=======================================================
Copy Coalescing in Chow
Wed Mar 21 22:38:15 CDT 2007
========================================================
I can do copy coalescing in chow. Here is how:

  //Walk the code 
  for each copy operation (a <- b)
    if  1) a.bb_list INTERSECT b.bb_list == the current block
       AND
        2) b.last_use == the current operation 
    then
    //can coalesce
    choose a (arbitrarly) to be the coalesced live range
    a.bb_list = a.bb_list UNION b.bb_list (vector set - O(n))
    a.fear_list = a.fear_list UNION b.fear_list (stl set - O(n))
    a.units = a.units UNION (b.units - unit for current block) (stl list -O(n))
    a.unit_for_this_block.last_use = max(a.last_use, b.last_use)

    //the values in the live units should be valid since we have done
    //no splitting yet there should not be any loads/stores necessary
    //at live range boundaries. The exception would be an uninitalized
    //value which could cause a live range to need a load at its first
    //use


========================================================
Enhanced Code Motion Observations
Fri Mar 23 00:09:43 CDT 2007
========================================================
So it turns out that EnhancedCodeMotion may not be so "enhanced". The
idea was that movement of loads and stores would always occur. Chow
says move a load up if there is at least a predecessor in the live
range so that you get some benefit by having a path where the load
does not need to occur. 

I changed that to say always move the load up. The intent was to
capture situations where we have a load and store to same location. We
would not catch the case where there is only one predecessor that
contains a store.

Now we have to leave the stores in and we can only replace the loads.
This is necessary for corectness. Running dead can make it profitable.
One curious thing is that enhanced code motions sometimes makes the
execution worse. I am not sure why but I suspect it is because of the
extra control flow (ecm always splits edges). We rely on clean to join
edges as necessary.

Turns out the enhanced is only profitable sometimes. Check out rkfs
for an example of where it hurts.

*EXPLORE MORE*
So changeing ECM to only move the load/store onto an edge is when
there are lrPreds (for sure profitable) or the pred count is 1 which
is to catch the specific case we are after.

        bool moveit =((PARAM_EnhancedCodeMotion 
                        && unit->block->pred_count == 1) 
                     || lrPreds > 0);

This allowed rkfs to actually change to be profitable under ECM.
However urand lost its profit to be equal with normal code motion. So
obviously this has an effect and we should look at how this parameter
effects other benchmarks.


========================================================
List of Chow Improvments
Fri Mar 23 01:22:13 CDT 2007
========================================================
1) Live Range coalescing
2) Enhanced Code Motion
3) Rematerialization
4) Smarter splitting - don't add useless blocks
5) Load directly into a register rather than load and then copy


========================================================
Interesting newsgroup post
Tue Apr 17 11:41:21 CDT 2007
========================================================
http://compilers.iecc.com/comparch/article/89-11-053
...
I think the Chow .VS. Chatin could be summarized as: Chow:
pre-generation(color on intermedite, partitioned register set) goal
directed allocation uses range splitting Chatin: post-generation
(color on instructions, uniform register usage) goal directed
spilling.  range is true live range, but no other splitting done.  And
the questions become:
  Which method has better information to do the cost analysis?
  Which method deals best with the "registers affect the code, code
    affects the registers" probem?
  When does spilling give sub-optimial results?
  What is the effect of range splitting?

========================================================
Chow generates dead code
Tue Apr 17 12:18:47 CDT 2007
========================================================
Chow does generate some dead code due to spill code for unallocated
local variables. If a live range is a local variable that gets spilled
and it is used before it needs to be loaded then the spill will be
dead. The code below shows this (from spline.i:202). The stores to
136,144 are never loaded anywhere. Dead code elimination deletes them

	66	dMUL	r130 r131 => r100 
  0 dSSTor  @SPILL_137(128) 8 128 r555 r100   #STORE 137_137
  66  dSUB  r103 r104 => r100 
  0 dSSTor  @SPILL_138(136) 8 136 r555 r100   #STORE 138_138
  0 dSLDor  @SPILL_137(128) 8 128 r555 => r101  #LOAD 137_137
  66  dDIV  r101 r100 => r100 
  0 dSSTor  @SPILL_139(144) 8 144 r555 r100   #STORE 139_139
  66  dSTor @*c 4 0 r6 r100 
  0 JMPl  LL0003 

One question about this why does the dSUB use r100 again? It should
choose r101 and in that case it would not need the load for 137_137
and the store to 137_137 would be dead as well.

========================================================
The problem with heat.i
Thu Apr 19 00:44:06 CDT 2007
========================================================
Two actually:
  1) there are SSA variables with no use-def chain entries. this makes
  my code unhappy. i put in a test to detect it. It looks like the
  variables are converted to NOPs but the SSA_def_count is never
  updated. blech.

  2) It uses a JMPT (jump table) which causes some problems with my
  enhanced code motion. When using enhanced code motion and moving a
  load onto the edge it will add a buffer block in between the JMPT
  and dest block. The JMPT instruction gets updated correctly, but the
  actual table (just some static data identified by a label) does not.
  This code shows what is happening.

                  L_TABLE:
                    L_BLK_1
                    L_BLK_2
                    L_BLK_3

                  SOME_BLOCK:
                    LD   x => r1 #index into the table
                    JMPT L_TABLE r1 [L_BLK_1 NEW_BLK L_BLK_3]

                  NEW_BLK:
                    LD
                    JMP L_BLK_2

                  L_BLK_2:
                    code code code ...

========================================================
Why we always split edges for EnhancedCodeMotion
Thu Apr 19 01:33:50 CDT 2007
========================================================
Ok, so why exactly must you always split edges when doing enhanced
code motion?  The reason is because with enhanced code motion we move
loads and stores onto edges even if there is just one successor in
order to catch pairs that can be converted to copies. So we
have code like


        L1:                       L1:
          .                         .
          .                         .
          .                         .
          ST Y, r2                  JMP L2
          JMP L2
                                  LD X, r2
            |                       |
            |         =====>        |
            |                       |
            v                       v
                                  ST Y, r2
           
          L2:                     L2:
            LD X, r2                .
            .                       .
            .                       .
            
Then we must create a new block on the edge. Otherwse the ST would
store r2 after LD loads a new value to r2 which is clearly incorrect
code.

========================================================
Why we can't just union live ranges at a copy
Sat Apr 21 23:03:27 CDT 2007
========================================================
This is probably really obvious, but I thought that we might be able
to just union live ranges at copy operations. Turns out this is not a
good idea. I got the idea after reading Briggs,Cooper,Torczan on
rematerialization where they say you can union copies if they are
defined by the same inst type. This does not run into problems because
it selectivly unions live ranges at phi nodes. If you are not
selective about it then you will run into bad times as the following
code shows:

                             x <- 
                            / \
                           /   \
                          /     \
                         /       \
                        /         \
                     y <- x      y <- z
                        \         /
                         \       /
                          \     /
                           \   /
                            \ /
                           y <- phi(y,y)
                           <- y
                           <- x
                           <- z

In this case we do not want to union x,y,z as they are not all part of
the same live range.
 
========================================================
Why we can't just union copies that have the same tag
Fri Apr 27 09:42:42 CDT 2007
========================================================
So even if we restrict unioning copies to be the same live range that
have the same tag we still run into problems. The issue is as follows:


B1:
  LD 1 -> r15
  CP r15 -> r16
  LD 2 -> r17

B2:
  r18 <- phi(r16, r19)
  DIV r18, r17, -> r19
  ADD r19, r15 -> ...
  .
  .
  BRANCH B2 B3

B3:
  .
  . 


If we try to union r15 and r16 to be the same live range then we get
trouble. The reason is that when we examine the phi node we see that
we should split out r16 from r18 so they are not the same live range.
But this means that any mention of r15 in B2 will put a live unit for
r16 in B2. But mentions of r18 will put a live unit for r18. This
means that we have a split live range that both have live units in the
same block. This causes problems with the way that we assign registers
since we assume that split live ranges are not overlapping.
Programatically we store based on orig_lrid -> reg. This means that lr
for r16 will think it is assigned a register in B2 that is the same as
the register for r18, even if we wanted to spill r16 in B2. This
causes incorrect code.

========================================================
Rematerialization status
Tue May  1 09:49:08 CDT 2007
========================================================
A first stab at rematerialization has been implemented, but it is not
working correctly. Need to figure out why. Some tests are giving
incorrect answers.

+ implement rematerialization
  new
  X run scc to get tags for each ssa name
  X examine each copy instruction, if the source and dest values have
    idential tags union them and remove the copy
  X examine operands of each phi-node. if an operand value has the
    same tag as the result value, union the values otherwise mark the
    result and phi node param as a split live range

  modify
  X modify Mapping::CreateLiveRangeMap
    so that live ranges that are split both map to the same orig live
    range (which should be the ufset of the phi node result) - this
    should not be done, actually
  X modify Chow::BuildInital to run through the split live ranges and
    and record the orig_lrid in the live range that was split out (the
    rematerializable part). do this right after AllocLiveRanges
  X mark the rematerilazble live ranges as such
  X modify spilling to load rematerialiazible values using loadI
  + modify the priority function to give less weight to
    rematerializable live ranges
  + tie rematerilize to enhanced code motion (paramerters)
 

========================================================
Rematerialization redo
Tue May 15 16:10:21 CDT 2007
========================================================
So I need to redo rematerialization becuase the current strategy is
not working. The problem is that if a live range is initially split
into three live ranges due to a rematerializable part on top and two
not rematerializable legs on the bottom then the orig_lrid field can
not be the same for all three live ranges. a more complicated
procedure is needed.

+ run union find as normal to build live ranges
  + keep an additional mapping for ssa_name --> setid which would be
    built by running union find selectively over the lattice
  + keep a set of live ranges to later be split (Splits())

+ build live ranges as normal through BuildInterferences()
+ split live ranges according to mapping made previously using the
  alternate ssa --> setid mapping
  - for each live range to be split
      for each block in the live range
        look up setid for ssa_name in the block
        keep a map from setid --> list of blocks

      choose the first element in the map (arbitrarily) to keep the
        same lrid
      for the other map elements create new live ranges using
        SplitFrom()
        if they are a constant then mark them as rematerializable
      for each block in the list mapping setid -> blocks
        TransferLiveUnit(origlr, newlr)

      rebulid the interferences
        for each fearlr in the interference list
          for each newly created lrs
            if fearlr interferes with newlr then AddInterference
          if fearlr not interfere with origlr then RemoveInterference


========================================================
Problem with rematerialization
Thu May 17 09:30:53 CDT 2007
========================================================
The problem with the implementation was that when we assign registers
we look up the live range based on the orig_lrid. This means that the
original live range is checked for rematerialization settings and none
of the split live ranges will ever be correctly checked. We need a way
to look at the actual live range when generating loads and stores.

The idea is to get rid of the color mapping and replace it with a map
from orig_lrid x block --> current_lr. Then the color can be grabbed
from the field in the current_lr. 

what about the reverse color map? it is ok since it already uses the
actual lrid, not the orig_lrid.


========================================================
Coloring algorithm observation
Thu May 17 12:01:46 CDT 2007
========================================================
Seems like we should be removing things from the constrained lists
when we assign a color or decide to spill but this is not done.  Why
am i not removing live ranges from the constrained lists when i
MarkNonCanidate and delete them? seems like they shoule be removed.


========================================================
Rematerialization implementation
Thu May 17 20:49:19 CDT 2007
========================================================
I figured out a way to make it so that loading a value at the start of
a life range that was split from a remat part can use a loadI to load
rather than a heavyweight load. The example I am thinking of is


   (A) x <- 1     x <- foo()
        \           /
         \         /
          \       /
           \     /
            \   /
             \ /
   (B)     z <- x + y

Say spill x defined at (A). Then we need to reload it for use at point
(B). Using enhanced code motion the load would be moved up to the edge
coming from (A). So when we need to insert the load we can check the
predecessor on that edge to see if it was once part of our live range
(using the blockmap) and if it is rematerializable. If yes to both
then generate a lightweight load, otherwise generate a heavyweight
load.


========================================================
LiveRange Trimming
Mon May 21 09:09:39 CDT 2007
========================================================
When done splitting a live range and it is time to trim. 

To Trim:
use worklist
add any node where there is a use or a def.
while worklist not empty
  remove node
  look at predecessors
    if predecessor is in LR and not yet marked
      mark predecessor
      put predecessor on worklist

go through all nodes and remove any node that is not marked


note: we may leave some unconstrained lrs on the constrained list
since we are deleting some live units from existence. this is not
incorrect, but is not optimal.

validate that trimming works on fmin.i for these live ranges
  tmp_22_120: only top four blocks
  tmp_22_22_split1: only use block
  tmp_13_13_split1: no blocks
  tmp_13_121: all the same blocks



========================================================
Changes needed to make double take to float regs
Tue May 22 15:18:12 CDT 2007
========================================================
HasColorAvailable()
  - if it is a double then check that num_regs - forbidden size >= 2

IsEntirelyUnColorable()
  - need to check num_regs - forbidden size >=2 
   <<and>>
   there are two regs next to eachother on even numbered boundary

AssignColor()
  - factor out choosing a color into a function in color.cc
  - if assigning to a double type then insert color,color+1 into
    forbidden
  - if asssigning to a double type then insert color,color+1 into
    used_color set for each block

IsConstrained()
  - if it is a double lr then check if fearlist.size() >= num_regs/2

ChooseSplitPoint()
  - check to make sure color is available in the block

IncludeInSplit()
  - check to make sure color is available in the unioned set

Add a command line switch to make double take two regs

========================================================
Chow mis-characterize when live ranges are constrained
Tue May 22 22:41:25 CDT 2007
========================================================
When you have a register type that must occupy two smaller registers
(such as a double taking two float registers) Chow says that you
should consider the bigger registers constrained if the have more
neighbors that 1/2 of the total registers due to the fact that they
take two registers.

In fact this is not good enough because you may have a live range that
is of the smaller register type that has less neighbors than the
number of available registers, but each neighbor requires double
registers. Thus if you have 7 neighbors and 14 registers then you
should consider yourself constrained. So actually if you have less
neighbors than number of registers you still need to count up the
possible required registers by type of neighbor.

========================================================
Things that are messed up with double registers
Tue May 22 22:49:26 CDT 2007
========================================================
1) temporary registers still only use one register for a double
X) counting the number of required registers in
CheckRegisterLimitFeasibility.
3) possibly when evicting registers from frame and JSR statements


========================================================
An alternate strategy for marking stores
Wed May 23 20:24:44 CDT 2007
========================================================
Trying an alternate strategy for marking stores by using reachability.

1) compute reachability so that there is a map from block -> set of
blocks that can be reached from that block. use iterative dataflow
worklist algorithm with equation:
  Reach(b) = b \cup_{s \in succ} Reach(s)

2) MarkStores()
  build union of reach sets for each block that contains a def
  intersect the union with the set of blocks in the live range
  for each block in the live range
    if block in defreach set then
      if successor block needs load
        need_store = true
      if successor block not in live range
        if live in at succsor block
          need_store = true


========================================================
Cost computation for stores not accurate
Wed May 23 20:47:32 CDT 2007
========================================================
When moving loads and stores the cost computation is not accurate for
stores because any store that can be deleted should not count against
the live range

========================================================
Implementing double registers in assign.cc
Thu May 24 13:16:11 CDT 2007
========================================================
GetFreeTempReg()
  540 - write function FindFreeReservedReg() to find a reserved reg
  using the pairing info

MarkRegisterUsed()
  make sure to mark the entire pair used

FindUsableReg()
  probably easiest to change roundRobinIt to an in and use indexing

RemoveUnusableReg()
  need to remove reg+width depedning on live range type

UnEvict()
  erase from regMap the width of the lr


---
GetFreeTmpReg()
  + in step 1 update the full width of reserved registers
  + combine steps 2,3 into one function: FindSutiableReg() and return
  null if no reg works
  + need to make a function for trimming potential registers that
  respects the type of the live range that we are evcting so the
  correct width of registers is trimmed
  + same with trimming already evicted registers
  + when choosing a register to evict you must still respect widths.
  so that means either evicting two allocated floats or one allocated
  double

UnEvict()
  + when resetting values for kicked assigned reg make sure to do it
  for the entire width of the live range

FindUsableReg()
  + pass in vector of candidate pool
  + accumulate candidates in a list based on a passed in predicate
  + choose from the candidates 

Invariants to maintain:
  (1) regMap contains a mapping from lrid to first reg used
  (2) reservedRegs accurately reflect the state of use in that if a
  lr needs r0 and r1 then the reserved reg for both will have the
  correct values in terms of origInst and purpose

FindCandidates()
  search_vector
  for(0, ub by width)
    found = true
    for 0,width by 1
      found = found and pred(seach_vector[r+w])
    if found
      candidates.push_back(candidate)
  return candidates

========================================================
Why chow reserves four registers
Wed Jun  6 23:12:54 CDT 2007
========================================================
(1) chow does not actually need to reserve two registers for
generating loads and stores since he is assuming that he can work on
values directly in memory. he wants to reserve registers used by the
code generator so that it can generate the low level code needed for
unallocated variables. he says at most 4 regs are needed (504). keith
says the four registers is due to an idiosyncracy of the mips
architecture in translating p-code (the IR used by chow) to machine
instructions.

========================================================
Local allocation
Thu Jun  7 22:28:48 CDT 2007
========================================================
After looking at the codes and talking with keith it is apperant that
some sort of local allocation is needed. As keith says a priority
based allocator will never select local values to keep in a reg. This
was killing us on at least one code, namely seval.i. The local values
were not given registers and so were generating loads and stores, even
though it would be possible to allocate them using temporary
registers.

implementing local allocation
I think that we can just beef up our Ensure algorithm a bit more to
make it work for local allocation as well. all that we need to do is
to change when we generate stores. right now we always generate a
store after a def, but we should be smarter about it by waiting to
generate a store when we need to reclaim the temporary register. this
means for each tmp reg we need to keep track of when it is dirty. then
in MarkRegisterUsed if we find an old mapping for the register we are
taking then we should generate a store if the reg is dirty and if it
needs the store. we can tell if it needs the store by looking at the
next use for the register. if it is a local live range then we can get
an exact number, if it is a global live range we check to see if it
has a use in this block or if it is live out at the end of the block.

also we need to take care when clearing registers out at the end of
basic blocks. if the tmpreg contains a global live range then we might
need to insert a store. if the live range is local then by definition
it ends at the block so no store is needed.

finding local values
in order to run local allocation we need to remove local variables
from the interference graph (perhaps we could have a yes/no param for
this as well). so we need a way to indicate which values are local
only. we can find local-only values by checking to see if a variable
is defined in a block and not live-in or live-out.
- convert to ssa
- for each ssa name check to see if it is live out in the block in
  which it was defined, if so then it is not a local name
- unconvert from ssa (SSA_Restore())
- split basic blocks
- convert again to ssa
- make sure that the ssa names still map to the same orig variable

command line options
-l #,# to specify the number of local registers per register class


========================================================
Local allocation - change details
Sat Jun  9 13:39:12 CDT 2007
========================================================
How to implement local allocation
X Move Assign::Init() into the RenameRegisters() function in chow.cc
X In Assign::Init() issue a call to BuildInstOrderingMap() that
  computes an id for each inst that gives an ordering that can be used
  in local allocation
X add a call to InitLocalAllocation() that calls ComputeDistanceMap at
  the top of the block loop in RenameRegs(). This needs a flag that is
  set by ResetTmpRegs when the map needs to be computed. The flag is
  set when reset_all is true.
X add a next_use,dirty,local field to the AssignedReg struct.
X in MarkRegisterUsed() set the next_use field based on the contents
  of dist_map[inst][lrid]. (rename to AssignRegister())
X update ResetAssignedReg() to clear the next_use,dirty field
X write the StoreIfNeeded() :: AssignedReg -> Void, which stores a
  live range in an AssignedReg if it is dirty and needed later.
  we should not be generating a store for every definition. we need to
  push the store generation to when we are kicking a value out of a
  register. in that case we should store if the kicked register contains
  a live range that is dirty AND its next use is in the future or it is
  non-local (could proably check live out here or something). this means
  that when we are clearing tmp regs at the end of a block then we also
  need to check if it is dirty and a non-local value and if so then
  generate a store.
X set default needMem to false, only need mem if dirty or evicted for
  def
X in ResetTmpReg() call StoreIfNeeded() for each reg 
X in FindSuitableTmp() call StoreIfNeeded() for the evicted reg
X update Bleady(). now you just need to look through the choices list
  and find the AssignedReg with the largest value for next_use. if any
  registers have a next_use of (-1) or have a next_use that is greater
  than the current inst should be Reset();
X i see no reason why regMap is needed? let's get rid of it. ok, well
  it lets us do a quick lookup to see if the live range is already in
  a register which would be a linear search otherwise.
AT THIS POINT YOU SHOULD BE ABLE TO ALLOCATE NORMALLY
X add a param to say whether local live ranges should be removed
X add a param to say how many local registers to reserve
X call FindLocalOnlyNames() in chow.main.cc
X add field to live range for local_only live ranges
X in AddLiveUnitOnce, if the orig_name is a local_name then mark the
  live range as local
X after BuildInitialLiveRanges() you should remove local live ranges
  from the interference graph (if removing locals)


1) why does not splitting bbs to 5 make fpppp run much better when i
give it a whole mess of registers for local allocation? seems like it
should be the same.
2) you allocate unconstrained live ranges no matter what, even if the
priority may not be worth it. should you reconsider?
3) move EnforceParam() to before dumping params so that params are
real

========================================================
Local allocaiton observations
Wed Jun 13 15:53:39 CDT 2007
========================================================
Some interesting outcomes from having implemented local allocation

1) codes are very specific about how many local registers are needed.
this means that having a single set of paramerters for a program are
not going to work. You will need to be able to give each function its
own set of paramerters to get the best performance.

2) (seval.i) trimming blocks combined with blindly allocating
unconstrained live ranges can hurt performance. this can happen when a
live range is allocated for a block where there is only a single def.
this causes a store at the end of the block so there is no total
savings. if it was unallocated then the local allocation could handle
it properly. see for example LR 48 in chow -r16 -b5 -g -t 1.i.


3) (seval.i) Global allocation of locals is not always able to make
the correct decisions. it may spill some global name because too many
local names are active in a block. if instead we only allocate global
regiseters and then use separate registers for locals we may in fact
be able to allocate without spilling. see for example LR 8 in

chow -r16 -b5 -g  1.i  (no alloc)
chow -r16 -b5 -l0,6 1.i 

4) if we strictly partition the registers into global and local then
it is likely that there will be some global registers that go unused
in a block. we should look for these unused registers and take
advantage of them. also, there may be some global registers which die
somewhere in the block. we should take advantage of those registers as
well.



========================================================
Detailed look at codes where chow is worse
Thu Jun 14 22:04:11 CDT 2007
========================================================
A look at some cases where chow is getting worse performance
using command:
chow -r32 -b5 -et

+ ilsw.i (3 spill insts)
chow -r32 -b5 -et -l2
gets rid of all spill insts

+ si.i (7 spill insts)
chow -r32 -b5 -et -l2 
gets rid of all but one spill for uninitialized local value

+ urand.i (0 spill insts)
here chaitin wins by rematerializaiton. even though no spilling is
necessary, rematerialization moves a loadI down to a different part of
the graph. this causes the block that held the loadI to be empty which
clean then took away. i am left with an extra JMP for that block and
thus incur an extra penalty for each call of urand.

+ zeroin.i (34 spill insts)
chow -r32 -b4 -etz -l0,4 1.i
this took some searching to find this string and it is interesting
that remat actually helps in this situation. ra has 10 spills here.
dynamic count gets us withing 3%
how not assigning unconstrained live ranges that have negative
priority can hurt you:
1) miss an opportuninty for ld/st --> cp 
2) miss opportunity for remat so that a store of the live range now
reaches a load of the live range where as the remat uses ldI so the
store reaches nothing and is removed by dead (not sure exactly what
this means, but it shows up in zeroin.i. it should go away if we
improve remat).


========================================================
Things you need to do to improve performance
Thu Jun 14 22:19:02 CDT 2007
========================================================
1) make use of unused global registers.

2) beef up rematerialization so that it does not kill you all the
time. i think the way to do this is to not split a remat live range
and give a remat live range lower priority so that if needed, it will
be more likely to be spilled. also need to take another look at how we
can improve how we insert spills for remat live ranges. we should not
insert stores in any remat live range. why not just say that the point
where we split the live range actually has a def so that it will
insert the needed stores for downstream live ranges. then we can put a
remat copy on the edge from the remat to non-remat and either do the
copy or use a loadI to load the value into the reg or insert a loadI
at the top of the block.

3) I do see a case where you are getting bit by having a live range
allocated in a block below you when it is in  a temp reg and you
insert a store and they insert a load instead of doing a copy. this
means you should probably insert that store onto the edge or insert a
copy instead.

=======================================================
Some observations from exhaustive search
Mon Jun 25 13:37:05 CDT 2007
========================================================
+ fmin
  1269 vs. 1225 (chow vs. ra)
  a number of configurations gave 1269, but that was the best that
  could be seen in the top 1000 results.

+ urand
  urand.i: get to 767 dynamic count which is no spilling, but as
  mentioned above ra wins by rematerialization code motion.

+ rkf45
was able to get rkf45 to perform better, but still not matchin ra.
  - fehl.i: got down to zero spills and same dynamic count(179,256) as
    ra with the params  -r32 -b10 -c3 -s1 -l 4,10 -e (among others)
  - rkfs.i: got down to 25 spills, though a param with 27 spills
    performed better in dynamic count. the lowest dynamic i saw
    (by just testing some low static spill params) was 80803 which is
    still higher than ra at (80483)
  - rkf45.i: same count as ra before starting

+ zeroin  
  944 vs. 916 (chow vs. ra)
  - zeroin.i: get to 944 dynamic count (although not with the top
    results in the zeroin results file which does not mean much).
    tried the top 1000 results. this is still more than the dynamic
    count for ra which is 916.
+ svd
  5427 vs. 5414 (chow vs. ra)
  several strings in the top 1000 (closer to the end starting around
  line 432). minimum 11 static spills.

+ fpppp
  - efill:
    2,778,807 vs. 2,753,388 (chow vs. ra)

+ doduc
  - colbur:
    349,011 vs. 343,239 (chow vs. ra)
    string is in the top 60 (#47)
  - repvid:
    194,860 vs. 189,298 (chow vs. ra)
  - ddeflu
    625,133 vs. 586,840 (chow vs. ra)

-- next runs --
file: ddeflu(3s), debflu(3s)

Q: why does fmin.i have 28 spill instructions when no opts are applied an
46 when standard opts are applied? what does the dynamic count
look like i wonder?
A: the dynamic count for no ops is much worse. not sure how it
compares to chaitin though.


=======================================================
Why I think chow should not do better with less registers
Mon Jul  2 20:47:30 CDT 2007
========================================================
It makes no sense that chow would perform better when there are less
registers. He must reserve 4 regs for local allocation and code
generation. He says himself that it might lead to inefficency, but it
is only a factor if the number of registers available is small.


I think a fair statement about chow is that it achieves good
allocation, but not the best. If my implementation was better we could
see how fast it is compared to others.


=======================================================
Optimistic chow
Tue Jul  3 14:16:01 CDT 2007
========================================================
I talked today with Tim about making chow optimisitic in its coloring.
The basic idea is that instead of constantly updating the constrained
lists we just optimistically remove them from the graph and if a split
would put them back on then don't do it, but just leave them
unconstrained. An example of where not pulling unconstrained nodes out
of the graph can hurt you is:

GRAPH:      ORDER:      COLOR:
A            -           
|
B            2           R
|
C            3           B
|
D            -
|
E            1           R
|
F            -

Here we see that D can not be given a color since C,E are both
assigned different colors. However we could color the graph just by
pulling out the nodes and pushing them onto a stack then coloring the
stack from top to bottom.

=======================================================
Implementing optimistic chow
Tue Jul  3 16:18:14 CDT 2007
=======================================================
Need to have some way to simplify the interference graph so that the
unconstrained live ranges cascade and continue to remove nodes that
become unconstrained by removing some of their neighbors. Then during
execution we optimistically keep all live ranges on the unconstrained
list and hope that splitting does not make it so they can not be
colored. This means that the constrained lists should not be updated
at all except to move constrained nodes over to the unconstrained
stack.

We still have to keep track of which nodes interfere and which colors
are forbidden so that we can correctly assign colors to unconstrained
nodes.  Now to assign colors to unconstrained we have to go in stack
order and at each point check to see if a color is available and if so
assigne it, otherwise mark it for spilling.

In order to find out which nodes can be simplified it would be best to
keep a count of simplified neighbors and how many colors they make
available to you. So basically just the simplified color count would
be sufficent. 

live_range.cc
+ add fileds to live_range class:
  simplified_neighbor_count
  simplified_width

chow.cc
+ create variable color_stack to be used for coloring on simplified
  graphs
+ when separating out the initial constr and unconstr live ranges you
  should check each live range to see if it is constrained. if not
  then put it on the color stack and update any neighbors to have
  another simplified neighbor. need to think about how to simplify the
  graph as it may need to be done in the correct order, that is to
  process the simplified nodes as they come up and then process thier
  neighbors that become simple as a result of removing them from the
  graph.
+ update functions so that we are no longer monkeying with constrained
  lists. any deletes from the constr_lrs should be preserved and 
  additions to unconstr_lrs should be changed to add to the coloring
  stack; at that point also you should try to add nodes that become
  unconstrained to the coloring stack as you go. deletes from
  unconstr_lrs should not be implemented.
    UpdateConstrainedLists
    UpdateConstrainedListsAfterDelete
    AddToCorrectConstrainedList
+ update the final coloring for unconstrained live ranges so that we
  first check to see if there is a color available and assign it if
  possible, otherwise mark the live range as spilled.


