=====
note
=====
question:

does splitting critical edges change the splitting of live ranges? for
example look at fmin.i where splitting critical edges makes chow fail
an insertion on multiple defs..

it seems that splitting critical edges can change the number of
interferences in a live range. This happens when the block for the 
split critical edge is added to a live range to extend its range. This
will happen when the live range is split and adds the extra block even
though it is not needed.

L1:
  z
  BRANCH L2 L3
  
L2:
  y
  GOTO L3

L3:
  y
  x
  END

with split critical edges in this case both x and z extend to the
dummy block L4, which increases their interferences. this can happen
with bad splitting (by adding a block when there is no subsequent use
(z) and adding a block before the first use (x)

L1:
  z
  BRANCH L2 L4
  
L2:
  y
  GOTO L3

L4:
  z
  x
  GOTO L3

L3:
  y
  x


=====
note
=====
it makes a big difference where you choose your split point,
otherwise you can end up with a bunch of live units with no uses and
no defs and the whole live range contains these useless units. i think
that is the cause of the "peeling" splitting we saw where it would
peel off on of the live units each time it would split, but that would
not help since it is a useless live unit


=====
note
=====
question:
why are we not putting the loads and stores in the right place? we are
calculating stores by looking at the uses that each def reaches. if it
reaches a use in another live range then we add a store. if it reaches
a use in the same live range that needs a load we add a store.

we compute loads by looking at the predecessor blocks. if the
predecessor is in another live range then we insert a load.

answer:
phi nodes were getting in the way. if a def reaches a use that is a
phi-node it is not a real use. we need to look at the uses that the
phi-node def reaches as well in order to find all the nodes that def
actually reaches.

=====
note
=====
speed up attemtps: 
 + use a set to for interferece "list" so that adding unique values is
 efficent (log n)

 + choose the starting point for the split much better
   - only split starting with a def or a use
   - split starting with an entry point if possible

 + a live range is uncolorable if all the live units where it actually
 has a use or a def have no available registers

 + only need to update interferences for the new and orig lr and those
 live ranges that they interfered with. can be done efficently by
 iterating over the origlr interferences and seeing what they now
 interfere with


=====
note
=====
observation:

it seems that the splitting algorithm can add live units to the split
live range even when there is no point. we split the live range by
looking for a place where it starts with a def or a use and then do a
bfs of the nodes in the origlr from there adding any node that does
not fill up the forbidden register set. now suppose that we don't get
to another use of the live range in any block that we add, this means
that if we allocate this split live range it could tie up all those
blocks even though it serves no purpose to have that register tied up
since there are no uses beyond the first.

I suspect that the priority function is designed to prevent this from
happening, but it is something to watch for.


=====
note
=====
question:

Would it be beneficial to split the BB at register to register copies?



=====
note
=====
Had a problem where a load was inserted for a live range because it
had a predecessor that was not in the live range, but no store was
inserted in any of the other blocks in the live range. Turns out the
load was requested because it was used in a phi-node, but no store was
generated because we were not counting phi-node uses. 

not sure how exactly this should be handeled. need to better figure
out where to insert loads and stores.


=====
note
=====
Need to solve two problems for inserting stores:
1) if the live range contains a def, figure out which blocks in the LR
that def reaches

2) for those blocks that def reaches, check if the successor block is
in the LR
  2.t) if it IS in the LR, then check if it needs a load
    2.t.t) if it does need a load then insert a store
    2.t.f) if it does not need a load then no store needed
  2.f) if it is NOT in the LR then check to see if the LR is live in
  at the successor block (only occurs after a split)
    2.f.t) if it is live in at successor then insert a store
    2.f.f) if it is not live in then no store needed


=========================
performance observation
=========================
Adding a coalesce pass  actually makes the performance decrease a bit
for the ra (Chaitin) code. This is not clear why, though the amount is
so small it is probably not meaningful.

On the other hand a coalesce pass helps me a lot on the order of
40,000 operations.


=================================
next steps
Thu Aug 17 15:20:08 CDT 2006
=================================
1) look at memory usage to see where we can possible free some memory
so that we do not use so much for allocation
2) implement the optimizations of placement of loads and stores.
  + review PRE as basis for the optimization
  + need to understand when this is done in the algorithm. Chow says
  to use it in order to have a more precise measurement of the
  priority function. so perhaps we can compute it as part of computing
  loads and stores, and just mark the load or store as movable, then
  when computing priority we don't have to count the cost???
3) Implement heuristics described in Chow paper for splitting. These
should improve allocation runtime speed. Chow said they did not help
allocation quality.
4) Need a peephole optimizer to take care of ST followed by immediate
LD
5) Figure out why ra does not give correct results on fpppp and seems
to loop forever on doduc (vgjyeh.i)
6) Why does Chaitin beat me so bad? Because he selects better
variables to store or is it something else?
7) Code up an example where the graph is colorable only through a
split. basically make the graph in Fig. 8 of chow's paper.
8) Check to make sure the coalesce pass is actually working
9) Review priority functions and weights given to functions to see
that priorites are computed sensibly.

Places where I think we can improve chow:
1) he uses memory to connect live ranges after he has split them. If
there was a way to notice that a store is loaded into a register in a
successor block then we could just do a register to register copy
rather than a ST/LD.

Possible splitting heruistics
1) don't add blocks if it makes the number of forbidden colors too
great (i.e. more than 1)

=================================
First Comparison
Thu Aug 17 15:24:23 CDT 2006
=================================
First comparison with the Chaitin allocator showed that it outpeformed
my Chow allocator by anywhere from 12%-133% (1.12-2.33 times better).
Brainstormed with Tim for a while about why this was the case. The
main result we thought of was that Chaitin was using a partitioned
register set while chow used a single register set. This means that
my allocator was having a lot more interferences than ra which could
be causing a lot more spilling.  Next steps to attack:

  1) make chow allocator use partitioned register set
  2) take a more detailed look at the code to see what is causing such
  a poor allocation. One identified problem is a ST followed directly
  by a LD.
  3) implement optimized placement of loads and stores





=================================
Second Comparison 
Wed Aug 23 15:52:28 CDT 2006
=================================
After the first comparison was found to be mostly bogus, I implemented
the partitioned register set for chow. This allows, for example
doubles and integers to be stored in separate register classes so that
they do not interfere.

Having done this the comparisons began.

1) dead | valnum | lazy |cprop | coalesce | chow -p
This showed that chow improved greatly on the fmm test set. It was 6%
better on fmin and mostly < 10% worse on all the others.

Spec was a different story. Chow was still doing quite bad going
anywhere from 1% to 115% worse. The oddball was matrix300 which only
was 1% worse. At this point I noticed that there were some small (42
op) routines that were doing worse. It was because Chow's version had
an extra dead instruction. It looks like ra does something to get rid
of dead instructions on its own. I decided to put a pass of dead on to
the end to see what would happen.

2) dead | valnum | lazy |cprop | coalesce | dead | chow -p
This helped quite a bit. Fmm all went down to being pretty even with
ra.

Spec got better, but still did quite bad on all the same suspects. 99%
better was ra on fpppp. I decided to pull out the big guns and limit
basic block sizes to see how much it helped

3) dead | valnum | lazy |cprop | coalesce | dead | chow -p
To my great disappointment Fmm went to shit. Most all of the programs
jumped up to more than 10% worse. It was not good.

Spec on the other hand did much better. fpppp dropped down to only 10%
worse. The highest was tomcatv at 18% worse. 

I was very suprised that reducing the basic block size did not help
everything get better (why did it make some worse?). I thought that it
would be useful to run tomcatv with various block sizes to see how it
performed. Ran with 5..30 in increments of 5. There was a sweet spot
at 25 that it actually performed better. Aha! So there was some hope.
I then looked at another small program that was doing worse (by 7
instructions). Turns out it was because of the extra JMP added when
the blocks were cleaved. I decided to run a pass of clean after to see
if it helped.

4) dead | valnum | lazy |cprop | coalesce | dead | chow -p | clean
Jackpot. This version was better on almost all programs and only very
slightly worse on some fmm (< .01%). Clean helped a bunch. 

But then I found out that ra was counting a double as using two float
registers so my results were not as good. Now rerunning experiments.

** why do I get different results than ra on the fmin which does not
spill???


============================== 
Second comparison explained
Thu Aug 24 16:24:01 CDT 2006
============================== 
The second comparison showed the two allocators to be approximately
equal. There is a problem though with how I am using temporaries. I am
not reserving the temporaries from the genearl pool, so I am really
cheating by having three-four extra registers. Need to fix that.


============================== 
Thu Aug 24 17:44:44 CDT 2006
============================== 
Notes from the conversation with Tim:

*) To run the register allocator (ra) with a reduced number of registers
use the following flags:
  -r[num] #number of registers
  -q      #"quality check" - make sure the number of registers will
          #work with the code(check the min number needed in the code)

*) Look at preston's thesis to see if you like the style of the literate
programming. Consider using nuweb for writing your thesis.

*) look at the code to make sure that it is doing what you want it to
do. The biggest challenge you will face in your experiments is
convincing people that you have implemented a chow allocator. And
not just any chow allocator, but one of decent quality. The best way
to to this is to come up with examples that show you are performing
like you would expect a chow allocator to perform. Take figures from
chow's paper and show how your allocator works just like the
examples in chow's paper says.  
  
  *) splitting example - can only color by splitting
  *) priority function example - should give higher priority to live
     range that you think 
  *) 
You can have a whole chapter in your thesis that shows these
examples along with links to your code that shows how you really did
implement chow.

*) Gather numbers on how often splitting helps you. We would like to
know when you split a live range whether you end up being able to
color part of it when you would have had to spill the entire thing if
you had not split.

*) Crank down the number of registers, try 16, 8 and see how the
algorithms perform.

*) Document your allocation parameters. We really need to have 4-5
params to have a decent search space. Better would be 6-7. Waterman
had 7 for his study of loop unrolling. So far we only have a couple
  1) basic block length
  2) priority function
  3) split small priority live ranges
  4) number of temporary register -- why would you want to reserve
     more?
  5) give clustered live ranges lower priority

  // these seem like performance improvements, not sure they should be
  // parameters
  6) select forbidden color from neighbor
  7) optimize load store placement
*) Research hard what improvements have been made to the chow
allocator. It is important that you find everything since missing a
reference could lead to people dismissing your work.

*) Read Waterman's study of loop unrolling. You will probably want to
use the same methodolgy in your adaptive chow allocator.


PLAN:
0) Write up a summary of the work you have done so far. Describe your
allocator and the choices you had to make. Also take the time to
document the allocation parameters. Look at preston's thesis and
literate programming.

1) Change your code to reserve registers for dealing with spilt code.
Now you cheat by assuming you have the correct number of registers
reserved, but this is not fair. You must reserve them from your
general pool.

2) Rerun the numbers to see how the allocators compare. Crank down the
number of registers and run those numbers as well. Gather the
statistics on how much splitting helps you.

3) Write the small code examples that mimic figures in chows paper and
shows that your allocator does what chow says.

4) Search the literature for how people have improved the chow
allocator.

5) Read Waterman's loop unrolling study

============================== 
Improvements to chow
Thu Aug 24 17:46:52 CDT 2006
============================== 
1) When we are splitting I think that it is possible that we could add
a bunch of basic blocks that are useless. When splitting we start at a
def and then do a bfs search along our successors, adding blocks as
we go. The problem is that if we never get to another use then all
those blocks we added were useless. They should not be part of the
live range since they contain no uses. Not sure if this is part of the
algorithm as specified by chow, or if it even crops up in any of our
tests.

2) One possible way to do coalescing might be to split the block at a
register to register copy and then not count that copy as an
interference. It would be cool to implement this and see if it works
and also to check to see if it would do some chaitain style
coalescing. Although to coalesce we would then need to find live
ranges that only interfere with a copy and say they are the same live
range. Merging live ranges would actually be a pretty simple operation
in chow I would think amounting to basically concatenating the
bb_lists.

3) Look for live ranges that have been split and then both parts 
assigned a register. You might have a case where you have a store and
then a load in a direct successor where the live range is split. In
this case you could replace it with a register to register copy
instead of the load/store. Implementing this would perhaps be tricky
because you would need to know that both are assigned a color and then
delete the store you inserted and replace it with a copy.


============================== 
Questions to answer
Tue Jan  9 10:32:27 CST 2007
============================== 
1) Chow claims that "splitting and spilling will most likely occur on
low priority live ranges"(pg. 515). Verify that this is the case.

2) Chow claims that using clustering as part of the metric for
computing priority would not make much of a difference, espically when
the number of registers is large (pg 513). Check to see if this is
true.

=================================
List of experiments
Tue Jan  9 10:59:25 CST 2007
Thu Aug 17 15:20:46 CDT 2006
=================================
+ Crank the size of a basic block down to 1 and compare the allocation
with Chaitin

+ Try inverting priority so that instead of allocating the most
beneficial live ranges to registers we allocate the most costly to
spill.

